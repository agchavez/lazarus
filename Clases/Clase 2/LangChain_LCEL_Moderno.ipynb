{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîó LangChain con LCEL - Gu√≠a Completa\n",
    "## Construyendo Aplicaciones Inteligentes con IA\n",
    "\n",
    "Este notebook te ense√±a a construir aplicaciones con LangChain usando **LCEL** (LangChain Expression Language).\n",
    "\n",
    "### ¬øQu√© aprender√°s?\n",
    "1. **Chains**: C√≥mo conectar componentes (prompts, LLMs, parsers)\n",
    "2. **Memory**: Dar memoria conversacional a tus aplicaciones\n",
    "3. **Tools**: Extender capacidades del LLM con herramientas personalizadas\n",
    "4. **Output Parsers**: Obtener datos estructurados del LLM\n",
    "5. **RAG**: Crear sistemas que consultan tus propios documentos\n",
    "\n",
    "### üéØ Objetivo del notebook:\n",
    "Al finalizar, sabr√°s crear aplicaciones de IA completas que pueden:\n",
    "- Mantener conversaciones con contexto\n",
    "- Usar herramientas externas (APIs, bases de datos, c√°lculos)\n",
    "- Consultar documentos propios (PDFs, textos)\n",
    "- Devolver datos estructurados (JSON, objetos validados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Instalaci√≥n de paquetes necesarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai python-dotenv langchain-core langchain-openai langchain-community \\\n",
    "    pypdf faiss-cpu -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuraci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Configuraci√≥n cargada\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    raise ValueError(\"‚ö†Ô∏è No se encontr√≥ OPENAI_API_KEY\")\n",
    "\n",
    "print(\"‚úÖ Configuraci√≥n cargada\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üîó PARTE 1: Chains - Conectar Componentes\n",
    "\n",
    "## ¬øQu√© son las Chains?\n",
    "**Chains** son secuencias de componentes conectados que procesan informaci√≥n paso a paso.\n",
    "\n",
    "## ¬øPara qu√© sirven?\n",
    "Permiten crear **pipelines de procesamiento**:\n",
    "- Input ‚Üí Formatear ‚Üí Procesar ‚Üí Transformar ‚Üí Output\n",
    "\n",
    "## Componentes b√°sicos:\n",
    "1. **Prompt**: Define las instrucciones para el LLM\n",
    "2. **LLM**: El modelo de IA que genera texto\n",
    "3. **Parser**: Procesa la salida del LLM\n",
    "\n",
    "## LCEL: El lenguaje para conectarlos\n",
    "Usamos el operador `|` (pipe) para conectar componentes:\n",
    "```python\n",
    "chain = prompt | llm | parser\n",
    "```\n",
    "\n",
    "Es como una tuber√≠a: los datos fluyen de izquierda a derecha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Chain B√°sica con LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîó CHAIN B√ÅSICA CON LCEL\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£ Creando el LLM...\n",
      "   ‚úÖ LLM creado (gpt-4o-mini)\n",
      "\n",
      "2Ô∏è‚É£ Creando el Prompt Template...\n",
      "   ‚úÖ Prompt Template creado\n",
      "   üìù Variables: producto, caracteristicas\n",
      "\n",
      "3Ô∏è‚É£ Creando el Output Parser...\n",
      "   ‚úÖ StrOutputParser creado (convierte a string)\n",
      "\n",
      "4Ô∏è‚É£ Conectando componentes con LCEL (operador |)...\n",
      "   ‚úÖ Chain creada!\n",
      "\n",
      "üìä FLUJO DE LA CHAIN:\n",
      "   Input ‚Üí Prompt ‚Üí LLM ‚Üí Parser ‚Üí Output\n",
      "           ‚Üì        ‚Üì      ‚Üì\n",
      "         Formatea  Genera  Extrae\n",
      "                   texto   string\n",
      "\n",
      "5Ô∏è‚É£ Ejecutando la chain...\n",
      "\n",
      "======================================================================\n",
      "üéØ DESCRIPCI√ìN GENERADA:\n",
      "======================================================================\n",
      "Descubre la potencia imbatible del Rotomartillo HILTI TE-70, la herramienta perfecta para los profesionales que demandan rendimiento y fiabilidad en cada proyecto. Dise√±ado para enfrentar los desaf√≠os m√°s exigentes en concreto, su motor de alta eficiencia garantiza una perforaci√≥n r√°pida y precisa, incluso en las condiciones m√°s duras.\n",
      "\n",
      "Con una ergonom√≠a optimizada y un peso equilibrado, el HILTI TE-70 te permite trabajar largas horas sin fatiga, mientras que su durabilidad excepcional asegura que siempre est√© listo para la pr√≥xima tarea. Ya sea en obras de construcci√≥n, remodelaciones o instalaciones industriales, este rotomartillo es tu aliado ideal.\n",
      "\n",
      "No te conformes con menos; elige la marca que los expertos conf√≠an. Con el Rotomartillo HILTI TE-70, eleva tu trabajo al siguiente nivel y haz que cada perforaci√≥n cuente. ¬°Hazte con el tuyo y siente la diferencia!\n",
      "\n",
      "üí° Nota: Todo esto en 1 l√≠nea ‚Üí chain = prompt | llm | parser\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîó CHAIN B√ÅSICA CON LCEL\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# PASO 1: Crear el LLM (el cerebro)\n",
    "print(\"\\n1Ô∏è‚É£ Creando el LLM...\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.7) # Entre 0 - 1 \n",
    "print(\"   ‚úÖ LLM creado (gpt-4o-mini)\")\n",
    "\n",
    "# PASO 2: Crear el Prompt (las instrucciones)\n",
    "print(\"\\n2Ô∏è‚É£ Creando el Prompt Template...\")\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un copywriter experto.\"),\n",
    "    (\"human\", \"Crea una descripci√≥n atractiva para: {producto}\\nCaracter√≠sticas: {caracteristicas}\")\n",
    "])\n",
    "print(\"   ‚úÖ Prompt Template creado\")\n",
    "print(\"   üìù Variables: producto, caracteristicas\")\n",
    "\n",
    "# PASO 3: Crear el Parser (procesa la salida)\n",
    "print(\"\\n3Ô∏è‚É£ Creando el Output Parser...\")\n",
    "parser = StrOutputParser()\n",
    "print(\"   ‚úÖ StrOutputParser creado (convierte a string)\")\n",
    "\n",
    "# PASO 4: CONECTAR TODO con el operador | (LCEL)\n",
    "print(\"\\n4Ô∏è‚É£ Conectando componentes con LCEL (operador |)...\")\n",
    "chain = prompt | llm | parser\n",
    "print(\"   ‚úÖ Chain creada!\")\n",
    "\n",
    "print(\"\\nüìä FLUJO DE LA CHAIN:\")\n",
    "print(\"   Input ‚Üí Prompt ‚Üí LLM ‚Üí Parser ‚Üí Output\")\n",
    "print(\"           ‚Üì        ‚Üì      ‚Üì\")\n",
    "print(\"         Formatea  Genera  Extrae\")\n",
    "print(\"                   texto   string\")\n",
    "\n",
    "# PASO 5: Ejecutar\n",
    "print(\"\\n5Ô∏è‚É£ Ejecutando la chain...\")\n",
    "resultado = chain.invoke({\n",
    "    \"producto\": \"Rotomartillo HILTI TE-70\",\n",
    "    \"caracteristicas\": \"Potente, ideal para concreto, marca profesional\"\n",
    "})\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéØ DESCRIPCI√ìN GENERADA:\")\n",
    "print(\"=\"*70)\n",
    "print(resultado)\n",
    "print(\"\\nüí° Nota: Todo esto en 1 l√≠nea ‚Üí chain = prompt | llm | parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Sequential Chain con LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üîó SEQUENTIAL CHAIN - Encadenar M√∫ltiples Operaciones\n",
      "======================================================================\n",
      "\n",
      "üí° CONCEPTO:\n",
      "   Una chain ejecuta su resultado y lo pasa a la siguiente\n",
      "   Chain 1 ‚Üí resultado ‚Üí Chain 2 ‚Üí resultado final\n",
      "\n",
      "1Ô∏è‚É£ CHAIN 1: Generar caracter√≠sticas t√©cnicas\n",
      "   ‚úÖ Chain 1 creada\n",
      "   üì• Input: producto\n",
      "   üì§ Output: lista de caracter√≠sticas\n",
      "\n",
      "2Ô∏è‚É£ CHAIN 2: Convertir caracter√≠sticas en pitch\n",
      "   ‚úÖ Chain 2 creada\n",
      "   üì• Input: caracteristicas\n",
      "   üì§ Output: pitch de ventas\n",
      "\n",
      "3Ô∏è‚É£ COMBINANDO las 2 chains...\n",
      "   Sintaxis LCEL:\n",
      "   {\"caracteristicas\": chain1} | chain2\n",
      "        ‚Üë                         ‚Üë\n",
      "   Ejecuta chain1           Usa el resultado\n",
      "   y lo asigna a            como input de\n",
      "   'caracteristicas'        chain2\n",
      "\n",
      "   ‚úÖ Chain secuencial creada!\n",
      "\n",
      "4Ô∏è‚É£ EJECUTANDO...\n",
      "\n",
      "============================================================\n",
      "Producto: Compactador de Rodillo 524 KGS\n",
      "============================================================\n",
      "\n",
      "‚è≥ Paso 1: Generando caracter√≠sticas...\n",
      "\n",
      "============================================================\n",
      "üéØ PITCH DE VENTAS FINAL:\n",
      "============================================================\n",
      "¬°Potencia y eficiencia en tus proyectos de construcci√≥n! Nuestro compactador de 524 kg combina un rodillo vibratorio para una compactaci√≥n superior, un ancho de trabajo vers√°til de 800-1200 mm y un motor potente de hasta 20 HP. Con controles ergon√≥micos, maximiza el confort y la productividad. ¬°Haz la elecci√≥n inteligente!\n",
      "\n",
      "üí° ¬øQu√© pas√≥ internamente?\n",
      "   1. chain_caracteristicas gener√≥ 5 caracter√≠sticas\n",
      "   2. El resultado se pas√≥ autom√°ticamente a chain_pitch\n",
      "   3. chain_pitch cre√≥ el pitch de ventas\n",
      "   4. Todo en una sola ejecuci√≥n!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"üîó SEQUENTIAL CHAIN - Encadenar M√∫ltiples Operaciones\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüí° CONCEPTO:\")\n",
    "print(\"   Una chain ejecuta su resultado y lo pasa a la siguiente\")\n",
    "print(\"   Chain 1 ‚Üí resultado ‚Üí Chain 2 ‚Üí resultado final\")\n",
    "\n",
    "# CHAIN 1: Generar caracter√≠sticas t√©cnicas\n",
    "print(\"\\n1Ô∏è‚É£ CHAIN 1: Generar caracter√≠sticas t√©cnicas\")\n",
    "prompt_caracteristicas = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Lista 5 caracter√≠sticas t√©cnicas clave de: {producto}\")\n",
    "])\n",
    "chain_caracteristicas = prompt_caracteristicas | llm | StrOutputParser()\n",
    "print(\"   ‚úÖ Chain 1 creada\")\n",
    "print(\"   üì• Input: producto\")\n",
    "print(\"   üì§ Output: lista de caracter√≠sticas\")\n",
    "\n",
    "# CHAIN 2: Crear pitch de ventas\n",
    "print(\"\\n2Ô∏è‚É£ CHAIN 2: Convertir caracter√≠sticas en pitch\")\n",
    "prompt_pitch = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Convierte estas caracter√≠sticas en un pitch de ventas (m√°ximo 50 palabras):\\n{caracteristicas}\")\n",
    "])\n",
    "chain_pitch = prompt_pitch | llm | StrOutputParser()\n",
    "print(\"   ‚úÖ Chain 2 creada\")\n",
    "print(\"   üì• Input: caracteristicas\")\n",
    "print(\"   üì§ Output: pitch de ventas\")\n",
    "\n",
    "# COMBINAR CHAINS usando LCEL\n",
    "print(\"\\n3Ô∏è‚É£ COMBINANDO las 2 chains...\")\n",
    "print(\"   Sintaxis LCEL:\")\n",
    "print(\"   {\\\"caracteristicas\\\": chain1} | chain2\")\n",
    "print(\"        ‚Üë                         ‚Üë\")\n",
    "print(\"   Ejecuta chain1           Usa el resultado\")\n",
    "print(\"   y lo asigna a            como input de\")\n",
    "print(\"   'caracteristicas'        chain2\")\n",
    "\n",
    "chain_completa = (\n",
    "    {\"caracteristicas\": chain_caracteristicas}\n",
    "    | chain_pitch\n",
    ")\n",
    "print(\"\\n   ‚úÖ Chain secuencial creada!\")\n",
    "\n",
    "# EJECUTAR\n",
    "print(\"\\n4Ô∏è‚É£ EJECUTANDO...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Producto: Compactador de Rodillo 524 KGS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚è≥ Paso 1: Generando caracter√≠sticas...\")\n",
    "resultado = chain_completa.invoke({\"producto\": \"Compactador de Rodillo 524 KGS\"})\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ PITCH DE VENTAS FINAL:\")\n",
    "print(\"=\"*60)\n",
    "print(resultado)\n",
    "\n",
    "print(\"\\nüí° ¬øQu√© pas√≥ internamente?\")\n",
    "print(\"   1. chain_caracteristicas gener√≥ 5 caracter√≠sticas\")\n",
    "print(\"   2. El resultado se pas√≥ autom√°ticamente a chain_pitch\")\n",
    "print(\"   3. chain_pitch cre√≥ el pitch de ventas\")\n",
    "print(\"   4. Todo en una sola ejecuci√≥n!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Parallel Chains (Ejecutar en paralelo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "‚ö° PARALLEL CHAINS - Ejecutar M√∫ltiples Chains AL MISMO TIEMPO\n",
      "======================================================================\n",
      "\n",
      "üí° CONCEPTO:\n",
      "   En vez de ejecutar chain1 ‚Üí chain2 (secuencial)\n",
      "   Ejecutamos chain1 + chain2 EN PARALELO (m√°s r√°pido)\n",
      "\n",
      "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "   ‚îÇ  Input  ‚îÇ\n",
      "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "        ‚îÇ\n",
      "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "   ‚ñº         ‚ñº\n",
      " Chain1    Chain2\n",
      "   ‚îÇ         ‚îÇ\n",
      "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "        ‚îÇ\n",
      "   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "   ‚îÇ Results ‚îÇ\n",
      "   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
      "\n",
      "1Ô∏è‚É£ CHAIN 1: Ventajas del producto\n",
      "   ‚úÖ Chain de ventajas creada\n",
      "\n",
      "2Ô∏è‚É£ CHAIN 2: Casos de uso\n",
      "   ‚úÖ Chain de casos de uso creada\n",
      "\n",
      "3Ô∏è‚É£ Creando RunnableParallel...\n",
      "   Sintaxis:\n",
      "   RunnableParallel(\n",
      "       nombre1=chain1,  ‚Üê Ejecuta en paralelo\n",
      "       nombre2=chain2   ‚Üê Ejecuta en paralelo\n",
      "   )\n",
      "\n",
      "   ‚úÖ RunnableParallel creada!\n",
      "   üì§ Retorna: {\"ventajas\": resultado1, \"casos_uso\": resultado2}\n",
      "\n",
      "4Ô∏è‚É£ EJECUTANDO...\n",
      "\n",
      "============================================================\n",
      "Producto: Rotomartillo TE-70\n",
      "============================================================\n",
      "\n",
      "‚ö° Ejecutando 2 chains en PARALELO...\n",
      "   (Esto es M√ÅS R√ÅPIDO que ejecutarlas una por una)\n",
      "\n",
      "============================================================\n",
      "‚úÖ VENTAJAS:\n",
      "============================================================\n",
      "El Rotomartillo TE-70 es una herramienta el√©ctrica popular utilizada para perforar y cincelar en diferentes materiales. Aqu√≠ tienes tres ventajas principales de este modelo:\n",
      "\n",
      "1. **Versatilidad**: El TE-70 es una herramienta 3 en 1 que puede perforar, cincelar y perforar con percusi√≥n, lo que lo hace adecuado para una amplia variedad de aplicaciones en construcci√≥n y remodelaci√≥n. Puedes utilizarlo en materiales como hormig√≥n, ladrillo y mamposter√≠a.\n",
      "\n",
      "2. **Potente rendimiento**: Con un motor de alta potencia, el TE-70 ofrece un rendimiento eficiente y r√°pido, permitiendo realizar trabajos exigentes sin esfuerzo. Esto se traduce en una mayor productividad y un acabado m√°s profesional en menos tiempo.\n",
      "\n",
      "3. **Ergonom√≠a y confort**: Este rotomartillo est√° dise√±ado con un enfoque en la comodidad del usuario. Su empu√±adura ergon√≥mica y su bajo peso facilitan el manejo y reducen la fatiga durante el uso prolongado, lo que es especialmente √∫til en trabajos de larga duraci√≥n.\n",
      "\n",
      "Estas caracter√≠sticas hacen del Rotomartillo TE-70 una opci√≥n atractiva para profesionales y aficionados al bricolaje.\n",
      "\n",
      "============================================================\n",
      "‚úÖ CASOS DE USO:\n",
      "============================================================\n",
      "El Rotomartillo TE-70 es una herramienta el√©ctrica vers√°til, ideal para diversas aplicaciones en la construcci√≥n y la remodelaci√≥n. Aqu√≠ te dejo tres casos de uso ideales para este equipo:\n",
      "\n",
      "1. **Perforaci√≥n en concreto y mamposter√≠a**: El TE-70 es perfecto para perforar agujeros en superficies de concreto, ladrillo y piedra. Esto es especialmente √∫til en la instalaci√≥n de anclajes, fijaci√≥n de estructuras o instalaci√≥n de sistemas el√©ctricos y de fontaner√≠a.\n",
      "\n",
      "2. **Demolici√≥n ligera**: Gracias a su capacidad de rotaci√≥n y percusi√≥n, el rotomartillo se puede utilizar en trabajos de demolici√≥n ligera, como la eliminaci√≥n de azulejos, paredes de ladrillo o estructuras de mamposter√≠a. Esto permite realizar reformas o remodelaciones de manera m√°s eficiente.\n",
      "\n",
      "3. **Fijaci√≥n de elementos pesados**: El TE-70 tambi√©n es ideal para la fijaci√≥n de elementos pesados, como estantes, barandillas o estructuras met√°licas. Su potencia y precisi√≥n permiten asegurar que los anclajes queden firmemente sujetos, garantizando la estabilidad y seguridad de las instalaciones.\n",
      "\n",
      "Estos casos de uso destacan la versatilidad y la potencia del Rotomartillo TE-70, haci√©ndolo una herramienta esencial para profesionales de la construcci√≥n y bricolaje.\n",
      "\n",
      "‚è±Ô∏è Tiempo de ejecuci√≥n: 6.03segundos\n",
      "\n",
      "üí° Beneficio:\n",
      "   Si cada chain toma 2 segundos:\n",
      "   - Secuencial: 2 + 2 = 4 segundos\n",
      "   - Paralelo: m√°x(2, 2) = ~2 segundos (50% m√°s r√°pido!)\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"‚ö° PARALLEL CHAINS - Ejecutar M√∫ltiples Chains AL MISMO TIEMPO\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\nüí° CONCEPTO:\")\n",
    "print(\"   En vez de ejecutar chain1 ‚Üí chain2 (secuencial)\")\n",
    "print(\"   Ejecutamos chain1 + chain2 EN PARALELO (m√°s r√°pido)\")\n",
    "print()\n",
    "print(\"   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"   ‚îÇ  Input  ‚îÇ\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "print(\"        ‚îÇ\")\n",
    "print(\"   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"   ‚ñº         ‚ñº\")\n",
    "print(\" Chain1    Chain2\")\n",
    "print(\"   ‚îÇ         ‚îÇ\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "print(\"        ‚îÇ\")\n",
    "print(\"   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê\")\n",
    "print(\"   ‚îÇ Results ‚îÇ\")\n",
    "print(\"   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\")\n",
    "\n",
    "# CHAIN 1: Generar ventajas\n",
    "print(\"\\n1Ô∏è‚É£ CHAIN 1: Ventajas del producto\")\n",
    "prompt_ventajas = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Lista 3 ventajas principales de: {producto}\")\n",
    "])\n",
    "chain_ventajas = prompt_ventajas | llm | StrOutputParser()\n",
    "print(\"   ‚úÖ Chain de ventajas creada\")\n",
    "\n",
    "# CHAIN 2: Generar casos de uso\n",
    "print(\"\\n2Ô∏è‚É£ CHAIN 2: Casos de uso\")\n",
    "prompt_casos = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Lista 3 casos de uso ideales para: {producto}\")\n",
    "])\n",
    "chain_casos = prompt_casos | llm | StrOutputParser()\n",
    "print(\"   ‚úÖ Chain de casos de uso creada\")\n",
    "\n",
    "# EJECUTAR EN PARALELO usando RunnableParallel\n",
    "print(\"\\n3Ô∏è‚É£ Creando RunnableParallel...\")\n",
    "print(\"   Sintaxis:\")\n",
    "print(\"   RunnableParallel(\")\n",
    "print(\"       nombre1=chain1,  ‚Üê Ejecuta en paralelo\")\n",
    "print(\"       nombre2=chain2   ‚Üê Ejecuta en paralelo\")\n",
    "print(\"   )\")\n",
    "\n",
    "chain_paralela = RunnableParallel(\n",
    "    ventajas=chain_ventajas,\n",
    "    casos_uso=chain_casos\n",
    ")\n",
    "print(\"\\n   ‚úÖ RunnableParallel creada!\")\n",
    "print(\"   üì§ Retorna: {\\\"ventajas\\\": resultado1, \\\"casos_uso\\\": resultado2}\")\n",
    "\n",
    "# EJECUTAR\n",
    "print(\"\\n4Ô∏è‚É£ EJECUTANDO...\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Producto: Rotomartillo TE-70\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚ö° Ejecutando 2 chains en PARALELO...\")\n",
    "print(\"   (Esto es M√ÅS R√ÅPIDO que ejecutarlas una por una)\")\n",
    "\n",
    "import time\n",
    "inicio = time.time()\n",
    "resultado = chain_paralela.invoke({\"producto\": \"Rotomartillo TE-70\"})\n",
    "tiempo = time.time() - inicio\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ VENTAJAS:\")\n",
    "print(\"=\"*60)\n",
    "print(resultado[\"ventajas\"])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ CASOS DE USO:\")\n",
    "print(\"=\"*60)\n",
    "print(resultado[\"casos_uso\"])\n",
    "\n",
    "print(f\"\\n‚è±Ô∏è Tiempo de ejecuci√≥n: {tiempo:.2f}segundos\")\n",
    "print(\"\\nüí° Beneficio:\")\n",
    "print(\"   Si cada chain toma 2 segundos:\")\n",
    "print(\"   - Secuencial: 2 + 2 = 4 segundos\")\n",
    "print(\"   - Paralelo: m√°x(2, 2) = ~2 segundos (50% m√°s r√°pido!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üí≠ PARTE 2: Memory - Dar Memoria a tus Aplicaciones\n",
    "\n",
    "## ¬øQu√© es Memory?\n",
    "Es la capacidad de **recordar conversaciones anteriores**. Sin memoria, cada interacci√≥n es independiente.\n",
    "\n",
    "## ¬øPara qu√© sirve?\n",
    "Crear **aplicaciones conversacionales** que:\n",
    "- Recuerdan el nombre del usuario\n",
    "- Mantienen contexto de la conversaci√≥n\n",
    "- Pueden hacer seguimiento de temas anteriores\n",
    "\n",
    "## Casos de uso:\n",
    "- ‚úÖ Chatbots de atenci√≥n al cliente\n",
    "- ‚úÖ Asistentes virtuales personalizados\n",
    "- ‚úÖ Tutores educativos que recuerdan el progreso\n",
    "- ‚úÖ Sistemas de recomendaci√≥n contextual\n",
    "\n",
    "## C√≥mo funciona:\n",
    "Guardamos el historial de mensajes (humano + IA) y lo pasamos como contexto en cada nueva interacci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Memory con RunnableWithMessageHistory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üó£Ô∏è CONVERSACI√ìN CON MEMORIA\n",
      "============================================================\n",
      "\n",
      "ü§ñ ¬°Hola, Mar√≠a! Claro, puedo ayudarte con eso. ¬øEst√°s buscando un demoledor para comprar o para alquilar? Adem√°s, ¬øtienes alg√∫n tipo espec√≠fico en mente, como un demoledor manual o uno el√©ctrico?\n",
      "\n",
      "ü§ñ La elecci√≥n del demoledor depende del tipo de trabajo que planeas realizar. Aqu√≠ te doy algunas recomendaciones:\n",
      "\n",
      "1. **Demoledor el√©ctrico**: Ideal para trabajos en interiores o en lugares donde no tienes acceso a una fuente de combustible. Son m√°s ligeros y silenciosos. Si vas a trabajar en proyectos peque√±os o medianos, un modelo de 5 a 10 kilovatios suele ser suficiente.\n",
      "\n",
      "2. **Demoledor de gasolina**: Estos son m√°s potentes y son ideales para trabajos al aire libre o en lugares sin electricidad. Si necesitas romper concreto, asfalto o hacer trabajos m√°s pesados, un modelo de este tipo ser√≠a m√°s adecuado.\n",
      "\n",
      "3. **Demoledor manual**: Si tienes un proyecto peque√±o y no quieres invertir en un equipo pesado, un demoledor manual puede ser suficiente. Es ideal para trabajos de detalle o √°reas peque√±as.\n",
      "\n",
      "4. **Martillo demoledor**: Si tu objetivo es romper superficies duras, un martillo demoledor puede ser la mejor opci√≥n. Son muy efectivos para romper concreto y asfalto.\n",
      "\n",
      "Si me das m√°s detalles sobre el tipo de trabajo que planeas realizar, puedo ofrecerte una recomendaci√≥n m√°s espec√≠fica.\n",
      "\n",
      "ü§ñ S√≠, Mar√≠a, lo recuerdo. Si necesitas m√°s informaci√≥n o si hay algo espec√≠fico en lo que pueda ayudarte, no dudes en dec√≠rmelo.\n",
      "\n",
      "üìù HISTORIAL:\n",
      "  human: Hola, me llamo Mar√≠a y necesito un demoledor...\n",
      "  ai: ¬°Hola, Mar√≠a! Claro, puedo ayudarte con eso. ¬øEst√°s buscando un demoledor para c...\n",
      "  human: ¬øCu√°l me recomiendas?...\n",
      "  ai: La elecci√≥n del demoledor depende del tipo de trabajo que planeas realizar. Aqu√≠...\n",
      "  human: ¬øRecuerdas mi nombre?...\n",
      "  ai: S√≠, Mar√≠a, lo recuerdo. Si necesitas m√°s informaci√≥n o si hay algo espec√≠fico en...\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "\n",
    "# Store para guardar historiales por sesi√≥n\n",
    "store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "# Prompt con placeholder para historial\n",
    "prompt_memoria = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Eres un asistente amable y profesional.\"),\n",
    "    MessagesPlaceholder(variable_name=\"history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# Chain con memoria\n",
    "chain_base = prompt_memoria | llm | StrOutputParser()\n",
    "\n",
    "chain_con_memoria = RunnableWithMessageHistory(\n",
    "    chain_base,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "# Conversaci√≥n\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üó£Ô∏è CONVERSACI√ìN CON MEMORIA\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "session_id = \"usuario_1\"\n",
    "config = {\"configurable\": {\"session_id\": session_id}}\n",
    "\n",
    "resp1 = chain_con_memoria.invoke(\n",
    "    {\"input\": \"Hola, me llamo Mar√≠a y necesito un demoledor\"},\n",
    "    config=config\n",
    ")\n",
    "print(f\"\\nü§ñ {resp1}\")\n",
    "\n",
    "resp2 = chain_con_memoria.invoke(\n",
    "    {\"input\": \"¬øCu√°l me recomiendas?\"},\n",
    "    config=config\n",
    ")\n",
    "print(f\"\\nü§ñ {resp2}\")\n",
    "\n",
    "resp3 = chain_con_memoria.invoke(\n",
    "    {\"input\": \"¬øRecuerdas mi nombre?\"},\n",
    "    config=config\n",
    ")\n",
    "print(f\"\\nü§ñ {resp3}\")\n",
    "\n",
    "# Ver historial\n",
    "print(\"\\nüìù HISTORIAL:\")\n",
    "history = get_session_history(session_id)\n",
    "for msg in history.messages:\n",
    "    print(f\"  {msg.type}: {msg.content[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Memory con Ventana (Trimming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ü™ü MEMORIA CON VENTANA (k=2)\n",
      "============================================================\n",
      "\n",
      "ü§ñ S√≠, mencionaste que vives en Honduras. Si necesitas informaci√≥n sobre d√≥nde comprar un compresor en tu pa√≠s o recomendaciones espec√≠ficas, h√°zmelo saber y con gusto te ayudar√©.\n",
      "\n",
      "üí° Solo recuerda las √∫ltimas 2 interacciones\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "# Funci√≥n para trimear mensajes (solo √∫ltimos K)\n",
    "def trim_messages(messages, k=4):\n",
    "    \"\"\"Mantiene solo los √∫ltimos K mensajes\"\"\"\n",
    "    return messages[-k:]\n",
    "\n",
    "# Store separado\n",
    "store_ventana = {}\n",
    "\n",
    "def get_window_history(session_id: str):\n",
    "    if session_id not in store_ventana:\n",
    "        store_ventana[session_id] = ChatMessageHistory()\n",
    "    return store_ventana[session_id]\n",
    "\n",
    "# Chain con ventana\n",
    "chain_ventana = RunnableWithMessageHistory(\n",
    "    prompt_memoria | llm | StrOutputParser(),\n",
    "    get_window_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"history\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ü™ü MEMORIA CON VENTANA (k=2)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "session_2 = \"usuario_2\"\n",
    "config_2 = {\"configurable\": {\"session_id\": session_2}}\n",
    "\n",
    "chain_ventana.invoke({\"input\": \"Me llamo Pedro\"}, config=config_2)\n",
    "chain_ventana.invoke({\"input\": \"Vivo en Honduras\"}, config=config_2)\n",
    "chain_ventana.invoke({\"input\": \"Necesito un compresor\"}, config=config_2)\n",
    "\n",
    "# Trimear manualmente\n",
    "history = get_window_history(session_2)\n",
    "history.messages = trim_messages(history.messages, k=4)\n",
    "\n",
    "resp = chain_ventana.invoke({\"input\": \"¬øRecuerdas de donde soy?\"}, config=config_2)\n",
    "print(f\"\\nü§ñ {resp}\")\n",
    "print(\"\\nüí° Solo recuerda las √∫ltimas 2 interacciones\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üõ†Ô∏è PARTE 3: Tools - Extender Capacidades del LLM\n",
    "\n",
    "## ¬øQu√© son las Tools?\n",
    "**Herramientas** son funciones de Python que el LLM puede usar para realizar tareas espec√≠ficas.\n",
    "\n",
    "## ¬øPor qu√© son necesarias?\n",
    "Los LLMs por s√≠ solos tienen limitaciones:\n",
    "- ‚ùå No pueden hacer c√°lculos matem√°ticos precisos\n",
    "- ‚ùå No pueden consultar bases de datos\n",
    "- ‚ùå No tienen acceso a informaci√≥n en tiempo real\n",
    "- ‚ùå No pueden ejecutar c√≥digo\n",
    "\n",
    "## ¬øPara qu√© sirven?\n",
    "Las tools **extienden** las capacidades del LLM:\n",
    "- ‚úÖ Hacer c√°lculos exactos\n",
    "- ‚úÖ Consultar APIs externas\n",
    "- ‚úÖ Leer/escribir en bases de datos\n",
    "- ‚úÖ Verificar disponibilidad de productos\n",
    "- ‚úÖ Obtener informaci√≥n actualizada (clima, precios, etc.)\n",
    "\n",
    "## Casos de uso:\n",
    "- Sistema de ventas que calcula precios con descuentos\n",
    "- Asistente que consulta inventario en tiempo real\n",
    "- Bot que obtiene informaci√≥n de APIs de terceros\n",
    "- Sistema que ejecuta consultas a bases de datos\n",
    "\n",
    "## C√≥mo funcionan:\n",
    "1. El LLM decide qu√© herramienta usar\n",
    "2. El LLM genera los par√°metros necesarios\n",
    "3. Se ejecuta la herramienta\n",
    "4. El resultado se le devuelve al LLM\n",
    "5. El LLM genera la respuesta final al usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import FAISS\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "\n",
    "VECTORSTORE_DIR = \"vectorstore_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "TOP_K_DOCUMENTS = 3\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "    \n",
    "    \n",
    "vectorstore = FAISS.load_local(VECTORSTORE_DIR, embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = vectorstore.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": TOP_K_DOCUMENTS}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Definir Tools con Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tools creadas con decorador @tool\n",
      "\n",
      "Herramientas disponibles: ['calcular_descuento', 'verificar_disponibilidad', 'calcular_fecha_entrega', 'buscar_info_producto']\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.tools import tool\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "@tool\n",
    "def calcular_descuento(precio: float, dias: int) -> dict:\n",
    "    \"\"\"Calcula el precio total con descuentos por volumen.\n",
    "    \n",
    "    Args:\n",
    "        precio: Precio por d√≠a en Lempiras\n",
    "        dias: N√∫mero de d√≠as de renta\n",
    "    \"\"\"\n",
    "    total = precio * dias\n",
    "    \n",
    "    if dias >= 30:\n",
    "        descuento = 0.20\n",
    "    elif dias >= 14:\n",
    "        descuento = 0.15\n",
    "    elif dias >= 7:\n",
    "        descuento = 0.10\n",
    "    else:\n",
    "        descuento = 0\n",
    "    \n",
    "    total_con_descuento = total * (1 - descuento)\n",
    "    ahorro = total - total_con_descuento\n",
    "    \n",
    "    return {\n",
    "        \"total_sin_descuento\": f\"L{total:.2f}\",\n",
    "        \"descuento_porcentaje\": f\"{descuento*100}%\",\n",
    "        \"total_con_descuento\": f\"L{total_con_descuento:.2f}\",\n",
    "        \"ahorro\": f\"L{ahorro:.2f}\"\n",
    "    }\n",
    "\n",
    "@tool\n",
    "def verificar_disponibilidad(equipo: str) -> str:\n",
    "    \"\"\"Verifica si un equipo est√° disponible en inventario.\n",
    "    \n",
    "    Args:\n",
    "        equipo: Nombre del equipo\n",
    "    \"\"\"\n",
    "    inventario = {\n",
    "        \"demoledor\": {\"disponible\": True, \"unidades\": 3},\n",
    "        \"rotomartillo\": {\"disponible\": True, \"unidades\": 5},\n",
    "        \"compactador\": {\"disponible\": False, \"unidades\": 0}\n",
    "    }\n",
    "    \n",
    "    for key, info in inventario.items():\n",
    "        if key in equipo.lower():\n",
    "            if info[\"disponible\"]:\n",
    "                return f\"‚úÖ {equipo} disponible. Stock: {info['unidades']} unidades\"\n",
    "            else:\n",
    "                return f\"‚ùå {equipo} agotado. Stock: {info['unidades']}\"\n",
    "    \n",
    "    return f\"‚ö†Ô∏è No encontrado: {equipo}\"\n",
    "\n",
    "@tool\n",
    "def calcular_fecha_entrega(dias: int) -> str:\n",
    "    \"\"\"Calcula la fecha de devoluci√≥n del equipo.\n",
    "    \n",
    "    Args:\n",
    "        dias: N√∫mero de d√≠as de renta\n",
    "    \"\"\"\n",
    "    \n",
    "    tiempo_transporte = 1  # d√≠as adicionales por transporte\n",
    "    dias += tiempo_transporte\n",
    "    \n",
    "    fecha = datetime.now() + timedelta(days=dias)\n",
    "    return f\"Fecha de devoluci√≥n: {fecha.strftime('%d/%m/%Y')}\"\n",
    "\n",
    "@tool\n",
    "def buscar_info_producto(producto: str) -> str:\n",
    "    \"\"\"Busca informaci√≥n de productos en el cat√°logo (precios, especificaciones, etc).\n",
    "    \n",
    "    Args:\n",
    "        producto: Nombre del producto a buscar\n",
    "    \"\"\"\n",
    "    # Usa invoke() en lugar de get_relevant_documents()\n",
    "    docs = retriever.invoke(producto)\n",
    "    if docs:\n",
    "        return docs[0].page_content[:500]\n",
    "    return \"No se encontr√≥ informaci√≥n del producto\"\n",
    "    \n",
    "tools = [calcular_descuento, verificar_disponibilidad, calcular_fecha_entrega, buscar_info_producto]\n",
    "\n",
    "print(\"‚úÖ Tools creadas con decorador @tool\")\n",
    "print(f\"\\nHerramientas disponibles: {[t.name for t in tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 LLM con Function Calling (Forma Moderna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ü§ñ LLM CON FUNCTION CALLING\n",
      "============================================================\n",
      "  Herramienta: calcular_fecha_entrega\n",
      "  Argumentos: {'dias': 10}\n",
      "  Resultado: Fecha de devoluci√≥n: 17/12/2025\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "# Bind tools al LLM (OpenAI Function Calling)\n",
    "llm_con_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Ejemplo de uso\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ü§ñ LLM CON FUNCTION CALLING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# El LLM decide qu√© herramienta usar\n",
    "#response = llm_con_tools.invoke(\"Necesito el rotomartillo para el martes pr√≥ximo\")\n",
    "response = llm_con_tools.invoke(\"Calcula el precio del demoledor para 30 d√≠as\")\n",
    "#response = llm_con_tools.invoke(\"Si rento por 10 d√≠as, ¬øcu√°ndo debo devolverlo?\")\n",
    "if response.tool_calls:\n",
    "    for tool_call in response.tool_calls:\n",
    "        print(f\"  Herramienta: {tool_call['name']}\")\n",
    "        print(f\"  Argumentos: {tool_call['args']}\")\n",
    "        \n",
    "        # Ejecutar la herramienta\n",
    "        tool_name = tool_call['name']\n",
    "        tool_args = tool_call['args']\n",
    "        \n",
    "        # Buscar la tool correspondiente\n",
    "        for tool in tools:\n",
    "            if tool.name == tool_name:\n",
    "                result = tool.invoke(tool_args)\n",
    "                print(f\"  Resultado: {result}\")\n",
    "else:\n",
    "    print(\"  (No se llam√≥ ninguna herramienta)\")\n",
    "    print(f\"  Respuesta directa: {response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Agent Loop Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "ü§ñ AGENTE MANUAL (SIN LANGCHAIN-CLASSIC)\n",
      "============================================================\n",
      "\n",
      "üîÑ Iteraci√≥n 1\n",
      "üîß Usando: buscar_info_producto({'producto': 'demoledor'})\n",
      "   Resultado: Disponibilidad: En stock\n",
      "DEMOLEDOR TE-800\n",
      "Precio: L550.00 por dia\n",
      "Martillo demoledor de alto rendimiento y robusto para trabajar en paredes y pisos. Marca HILTI modelo TE-800.\n",
      "Disponibilidad: En stock\n",
      "DEMOLEDOR TE-1000\n",
      "Precio: L800.00 por dia\n",
      "Martillo rompedor versatil para tareas de rotura de suelos y aplicaciones ocasionales de paredes. Marca HILTI modelo\n",
      "TE-1000.\n",
      "Disponibilidad: En stock\n",
      "DEMOLEDOR TE-2000\n",
      "üîß Usando: calcular_fecha_entrega({'dias': 15})\n",
      "   Resultado: Fecha de devoluci√≥n: 22/12/2025\n",
      "\n",
      "üîÑ Iteraci√≥n 2\n",
      "üîß Usando: calcular_descuento({'precio': 550, 'dias': 15})\n",
      "   Resultado: {'total_sin_descuento': 'L8250.00', 'descuento_porcentaje': '15.0%', 'total_con_descuento': 'L7012.50', 'ahorro': 'L1237.50'}\n",
      "\n",
      "üîÑ Iteraci√≥n 3\n",
      "‚úÖ Respuesta final: Para rentar un **demoledor** (modelo TE-800) por **15 d√≠as** el costo ser√≠a:\n",
      "\n",
      "- **Precio sin descuento:** L8250.00\n",
      "- **Descuento aplicado:** 15%\n",
      "- **Precio total con descuento:** L7012.50\n",
      "- **Ahorro:** L1237.50\n",
      "\n",
      "La **fecha de entrega** del equipo ser√≠a el **22 de diciembre de 2025**.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, ToolMessage\n",
    "\n",
    "def ejecutar_agente(pregunta: str, max_iterations: int = 5):\n",
    "    \"\"\"Agente simple que usa tools sin langchain-classic\"\"\"\n",
    "    \n",
    "    messages = [HumanMessage(content=pregunta)]\n",
    "    \n",
    "    for i in range(max_iterations):\n",
    "        print(f\"\\nüîÑ Iteraci√≥n {i+1}\")\n",
    "        \n",
    "        # LLM decide\n",
    "        response = llm_con_tools.invoke(messages)\n",
    "        messages.append(response)\n",
    "        \n",
    "        # Si no hay tool calls, terminamos\n",
    "        if not response.tool_calls:\n",
    "            print(f\"‚úÖ Respuesta final: {response.content}\")\n",
    "            return response.content\n",
    "        \n",
    "        # Ejecutar tools\n",
    "        for tool_call in response.tool_calls:\n",
    "            tool_name = tool_call['name']\n",
    "            tool_args = tool_call['args']\n",
    "            \n",
    "            print(f\"üîß Usando: {tool_name}({tool_args})\")\n",
    "            \n",
    "            # Buscar y ejecutar tool\n",
    "            for tool in tools:\n",
    "                if tool.name == tool_name:\n",
    "                    result = tool.invoke(tool_args)\n",
    "                    print(f\"   Resultado: {result}\")\n",
    "                    \n",
    "                    # Agregar resultado a mensajes\n",
    "                    messages.append(\n",
    "                        ToolMessage(\n",
    "                            content=str(result),\n",
    "                            tool_call_id=tool_call['id']\n",
    "                        )\n",
    "                    )\n",
    "    \n",
    "    return \"Max iteraciones alcanzadas\"\n",
    "\n",
    "# Probar el agente\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ü§ñ AGENTE MANUAL (SIN LANGCHAIN-CLASSIC)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "resultado = ejecutar_agente(\n",
    "    \"¬øCu√°nto cuesta rentar un demoledor por 15 d√≠as, que fecha de entrega tendria?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä PARTE 4: Output Parsers - Estructurar Datos\n",
    "\n",
    "## ¬øQu√© son los Output Parsers?\n",
    "Componentes que **convierten** la respuesta de texto del LLM en **datos estructurados**.\n",
    "\n",
    "## ¬øCu√°l es el problema?\n",
    "Por defecto, el LLM devuelve texto libre:\n",
    "```\n",
    "\"El producto cuesta L750 por d√≠a y est√° disponible\"\n",
    "```\n",
    "\n",
    "Esto es dif√≠cil de procesar program√°ticamente.\n",
    "\n",
    "## ¬øPara qu√© sirven?\n",
    "Obtener **datos estructurados** que puedes usar en tu aplicaci√≥n:\n",
    "```json\n",
    "{\n",
    "  \"precio\": 750,\n",
    "  \"disponible\": true,\n",
    "  \"moneda\": \"L\"\n",
    "}\n",
    "```\n",
    "\n",
    "## Casos de uso:\n",
    "- ‚úÖ Extraer informaci√≥n de productos (nombre, precio, stock)\n",
    "- ‚úÖ Clasificar texto (categor√≠as, sentimientos)\n",
    "- ‚úÖ Generar formularios estructurados\n",
    "- ‚úÖ Crear datos para bases de datos\n",
    "- ‚úÖ Validar tipos de datos\n",
    "\n",
    "## Tipos de parsers:\n",
    "1. **JsonOutputParser**: Convierte a JSON/diccionarios\n",
    "2. **PydanticOutputParser**: Valida tipos con Pydantic\n",
    "3. **StructuredOutput**: Usa funci√≥n nativa de OpenAI (m√°s confiable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 JSON Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä SALIDA JSON:\n",
      "{'nombre': 'Rotomartillo TE-70', 'precio': 'L750/d√≠a', 'categoria': 'herramientas', 'disponible': True}\n",
      "\n",
      "Nombre: Rotomartillo TE-70\n",
      "Disponible: True\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Producto(BaseModel):\n",
    "    nombre: str = Field(description=\"Nombre del producto\")\n",
    "    precio: str = Field(description=\"Precio en Lempiras\")\n",
    "    categoria: str = Field(description=\"Categor√≠a\")\n",
    "    disponible: bool = Field(description=\"Disponibilidad\")\n",
    "\n",
    "parser = JsonOutputParser(pydantic_object=Producto)\n",
    "\n",
    "prompt_json = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extrae informaci√≥n y devuelve JSON.\\n{format_instructions}\"),\n",
    "    (\"human\", \"{text}\")\n",
    "])\n",
    "\n",
    "chain_json = (\n",
    "    prompt_json.partial(format_instructions=parser.get_format_instructions())\n",
    "    | llm\n",
    "    | parser\n",
    ")\n",
    "\n",
    "resultado = chain_json.invoke({\n",
    "    \"text\": \"Rotomartillo TE-70, L750/d√≠a, herramientas, en stock\"\n",
    "})\n",
    "\n",
    "print(\"\\nüìä SALIDA JSON:\")\n",
    "print(resultado)\n",
    "print(f\"\\nNombre: {resultado['nombre']}\")\n",
    "print(f\"Disponible: {resultado['disponible']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Structured Output (OpenAI Native)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üéØ OBJETO PYDANTIC:\n",
      "Nombre: Demoledor TE-3000 HILTI\n",
      "Precio: L1100.0\n",
      "Caracter√≠sticas: ['Martillo rompedor potente', 'Dise√±ado para concreto pesado', 'Ideal para trabajos de demolici√≥n', 'F√°cil de manejar', 'Durabilidad garantizada']\n",
      "Categor√≠a: Herramientas de construcci√≥n\n",
      "Disponible: True\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "class ProductoCompleto(BaseModel):\n",
    "    \"\"\"Informaci√≥n completa de un producto\"\"\"\n",
    "    nombre: str = Field(description=\"Nombre del producto\")\n",
    "    precio: float = Field(description=\"Precio por d√≠a en Lempiras\")\n",
    "    caracteristicas: List[str] = Field(description=\"Lista de caracter√≠sticas\")\n",
    "    disponible: bool = Field(description=\"Si est√° disponible\")\n",
    "    categoria: str = Field(description=\"Categor√≠a del producto\")\n",
    "\n",
    "# Usar structured output nativo de OpenAI\n",
    "llm_structured = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0\n",
    ").with_structured_output(ProductoCompleto)\n",
    "\n",
    "prompt_structured = ChatPromptTemplate.from_messages([\n",
    "    (\"human\", \"Extrae informaci√≥n del producto: {descripcion}\")\n",
    "])\n",
    "\n",
    "chain_structured = prompt_structured | llm_structured\n",
    "\n",
    "producto = chain_structured.invoke({\n",
    "    \"descripcion\": \"Demoledor TE-3000 HILTI, martillo rompedor potente para concreto pesado, L1100 por d√≠a, disponible en stock\"\n",
    "})\n",
    "\n",
    "print(\"\\nüéØ OBJETO PYDANTIC:\")\n",
    "print(f\"Nombre: {producto.nombre}\")\n",
    "print(f\"Precio: L{producto.precio}\")\n",
    "print(f\"Caracter√≠sticas: {producto.caracteristicas}\")\n",
    "print(f\"Categor√≠a: {producto.categoria}\")\n",
    "print(f\"Disponible: {producto.disponible}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# üìö Resumen del Notebook\n",
    "\n",
    "## ‚úÖ Lo que aprendiste:\n",
    "\n",
    "### 1. **Chains con LCEL**\n",
    "- Conectar componentes con el operador `|`\n",
    "- Crear pipelines de procesamiento\n",
    "- Ejecutar chains secuenciales y paralelas\n",
    "\n",
    "**Sintaxis clave:**\n",
    "```python\n",
    "chain = prompt | llm | parser\n",
    "resultado = chain.invoke(input)\n",
    "```\n",
    "\n",
    "### 2. **Memory**\n",
    "- Dar memoria conversacional a aplicaciones\n",
    "- Mantener contexto entre interacciones\n",
    "- Implementar diferentes estrategias (ventana, resumen)\n",
    "\n",
    "**Sintaxis clave:**\n",
    "```python\n",
    "chain_con_memoria = RunnableWithMessageHistory(chain, get_history)\n",
    "```\n",
    "\n",
    "### 3. **Tools**\n",
    "- Extender capacidades del LLM\n",
    "- Crear funciones personalizadas\n",
    "- Usar Function Calling de OpenAI\n",
    "\n",
    "**Sintaxis clave:**\n",
    "```python\n",
    "@tool\n",
    "def mi_herramienta(param: tipo) -> tipo:\n",
    "    \"\"\"Descripci√≥n de qu√© hace\"\"\"\n",
    "    return resultado\n",
    "\n",
    "llm_con_tools = llm.bind_tools([mi_herramienta])\n",
    "```\n",
    "\n",
    "### 4. **Output Parsers**\n",
    "- Obtener datos estructurados del LLM\n",
    "- Validar tipos con Pydantic\n",
    "- Usar structured output nativo\n",
    "\n",
    "**Sintaxis clave:**\n",
    "```python\n",
    "parser = JsonOutputParser(pydantic_object=MiClase)\n",
    "chain = prompt | llm | parser\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Pr√≥ximos Pasos\n",
    "\n",
    "### Practica creando:\n",
    "1. Un chatbot con memoria para tu negocio\n",
    "2. Un sistema RAG sobre tus propios documentos\n",
    "3. Un asistente con tools personalizadas\n",
    "4. Una aplicaci√≥n que combine todo lo anterior\n",
    "\n",
    "### Recursos adicionales:\n",
    "- [Documentaci√≥n de LangChain](https://python.langchain.com/)\n",
    "- [Cookbook con ejemplos](https://github.com/langchain-ai/langchain/tree/master/cookbook)\n",
    "- [Comunidad en Discord](https://discord.gg/langchain)\n",
    "\n",
    "---\n",
    "\n",
    "## üí° Consejos Finales\n",
    "\n",
    "### ‚úÖ Mejores pr√°cticas:\n",
    "1. **Empieza simple**: Primero haz que funcione, luego optimiza\n",
    "2. **Prueba iterativamente**: Ejecuta cada componente por separado\n",
    "3. **Usa verbose**: Ayuda a debuggear (`llm.invoke(..., verbose=True)`)\n",
    "4. **Documenta tus tools**: El LLM usa las descripciones para decidir\n",
    "5. **Monitorea costos**: Usa callbacks para trackear tokens\n",
    "\n",
    "### ‚ö†Ô∏è Errores comunes:\n",
    "1. Descripciones de tools poco claras ‚Üí El LLM no sabe cu√°ndo usarlas\n",
    "2. Chunks muy grandes en RAG ‚Üí Excede l√≠mite de contexto\n",
    "3. No validar inputs de tools ‚Üí Errores en runtime\n",
    "4. Olvidar formatear contexto en RAG ‚Üí El LLM recibe mal los docs\n",
    "5. No limitar iteraciones en loops ‚Üí Puede quedar en loop infinito\n",
    "\n",
    "---\n",
    "\n",
    "**¬°√âxito en tus proyectos con LangChain! üéì**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "curos-ia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
