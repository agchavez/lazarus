# ğŸ“š GuÃ­a de Estudio - Clase 3: OptimizaciÃ³n de Agentes RAG

## ğŸ¯ Objetivo de esta guÃ­a
Esta guÃ­a te ayudarÃ¡ a prepararte para la Clase 3, asegurando que tengas los conocimientos necesarios para aprovechar al mÃ¡ximo el contenido.

---

## ğŸ“‹ PARTE 1: Repaso de Fundamentos (Clase 1 y 2)

### 1.1 Conceptos de RAG
- [ ] **Â¿QuÃ© es RAG?** (Retrieval-Augmented Generation)
  - Entender el flujo: Retrieval â†’ Augmentation â†’ Generation
  - Diferencia entre RAG y LLM sin contexto
  - Ventajas de RAG sobre fine-tuning

- [ ] **Componentes de RAG**
  - Vectorstore (FAISS)
  - Embeddings (text-embedding-3-small)
  - Retriever (bÃºsqueda por similaridad)
  - LLM (gpt-4o-mini)

- [ ] **Proceso de VectorizaciÃ³n**
  - CÃ³mo se crean los embeddings
  - QuÃ© es un chunk y por quÃ© dividimos documentos
  - BÃºsqueda por similaridad coseno

### 1.2 LangChain BÃ¡sico
- [ ] **Chains con LCEL**
  - Operador `|` (pipe) para conectar componentes
  - Sintaxis: `prompt | llm | parser`
  - Diferencia entre `.invoke()` y `.stream()`

- [ ] **Prompts**
  - ChatPromptTemplate
  - Variables en prompts: `{variable}`
  - System vs Human messages

- [ ] **Callbacks**
  - Para quÃ© sirven los callbacks
  - `get_openai_callback()` para tracking de costos

### 1.3 OpenAI API
- [ ] **Modelos disponibles**
  - gpt-4o-mini (rÃ¡pido y econÃ³mico)
  - gpt-4o (mÃ¡s potente, mÃ¡s caro)
  - Diferencias de precio entre modelos

- [ ] **Tokens**
  - QuÃ© es un token (â‰ˆ 0.75 palabras en inglÃ©s)
  - Tokens de input vs output
  - CÃ³mo contar tokens en espaÃ±ol

- [ ] **Costos**
  - Estructura de precios de OpenAI
  - Input tokens vs Output tokens
  - CÃ³mo calcular costo por consulta

---

## ğŸ“‹ PARTE 2: Conceptos Nuevos de Clase 3

### 2.1 Prompt Engineering â­ IMPORTANTE

#### Â¿QuÃ© es?
El arte y ciencia de diseÃ±ar instrucciones efectivas para el LLM.

#### Estudiar:
- [ ] **Componentes de un buen prompt**
  - Contexto claro
  - Instrucciones especÃ­ficas
  - Formato de salida esperado
  - Restricciones y lÃ­mites

- [ ] **TÃ©cnicas de Prompting**

  **Zero-shot:**
  ```
  "Responde la pregunta: Â¿QuÃ© es RAG?"
  ```
  âœ… Simple
  âŒ Puede dar respuestas genÃ©ricas

  **Few-shot Learning:**
  ```
  "Ejemplos:
   P: Â¿Precio del TE-500? R: L320 por dÃ­a
   P: Â¿Precio del TE-70? R: L750 por dÃ­a

   P: Â¿Precio del TE-2000?"
  ```
  âœ… El LLM aprende del formato
  âœ… Respuestas mÃ¡s consistentes

  **Chain of Thought (CoT):**
  ```
  "Piensa paso a paso:
   1. Â¿QuÃ© pregunta el usuario?
   2. Â¿QuÃ© informaciÃ³n tengo?
   3. Â¿CuÃ¡l es la mejor respuesta?"
  ```
  âœ… Mejora razonamiento
  âœ… Reduce alucinaciones

- [ ] **Role Playing**
  ```
  "Eres un especialista tÃ©cnico con 25 aÃ±os de experiencia..."
  ```
  âœ… Da contexto de expertise
  âœ… Mejora el tono de respuestas

- [ ] **Restricciones**
  ```
  "SOLO usa informaciÃ³n del contexto"
  "MÃ¡ximo 3 pÃ¡rrafos"
  "Si no sabes, di 'no tengo informaciÃ³n'"
  ```
  âœ… Previene alucinaciones
  âœ… Controla longitud de respuestas

#### ğŸ“– Recursos para estudiar:
- [OpenAI Best Practices](https://platform.openai.com/docs/guides/prompt-engineering)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [Learn Prompting](https://learnprompting.org/)

---

### 2.2 ParÃ¡metros del LLM â­ IMPORTANTE

#### Temperature (0.0 - 1.0)
Controla la aleatoriedad de las respuestas.

- [ ] **Temperature = 0.0**
  - Determinista (siempre la misma respuesta)
  - Uso: ClasificaciÃ³n, datos estructurados
  - Ejemplo: "Categoriza este producto"

- [ ] **Temperature = 0.3**
  - Consistente pero con variaciÃ³n mÃ­nima
  - Uso: **AtenciÃ³n al cliente, FAQ**
  - Ejemplo: Responder preguntas sobre productos

- [ ] **Temperature = 0.7**
  - Creativo y variado
  - Uso: GeneraciÃ³n de contenido, marketing
  - Ejemplo: "Escribe un slogan creativo"

- [ ] **Temperature = 1.0**
  - Muy aleatorio
  - Uso: Brainstorming, ideas originales
  - Ejemplo: "Dame 20 ideas de productos nuevos"

#### Max Tokens
LÃ­mite mÃ¡ximo de tokens en la respuesta.

- [ ] **Â¿CÃ³mo elegir?**
  - Respuestas cortas: 100-200 tokens
  - Respuestas normales: 300-500 tokens
  - Respuestas largas: 500-1000 tokens

- [ ] **Impacto en costos**
  - MÃ¡s tokens = Mayor costo
  - Ajustar al mÃ­nimo necesario
  - Monitorear en producciÃ³n

#### Top P (Nucleus Sampling)
Alternativa a temperature (no se usa en Clase 3, pero es bueno saberlo).

---

### 2.3 MediciÃ³n de Costos â­ IMPORTANTE

#### Â¿Por quÃ© medir?
- [ ] Control de presupuesto
- [ ] OptimizaciÃ³n de recursos
- [ ] ComparaciÃ³n de configuraciones
- [ ] ProyecciÃ³n de costos a escala

#### MÃ©tricas clave:
- [ ] **Tokens de Prompt (Input)**
  - Lo que envÃ­as al LLM
  - Incluye: system message + contexto + pregunta
  - Precio: ~$0.15 / 1M tokens (gpt-4o-mini)

- [ ] **Tokens de Completion (Output)**
  - Lo que el LLM genera
  - Solo la respuesta
  - Precio: ~$0.60 / 1M tokens (gpt-4o-mini)

- [ ] **Tokens Totales**
  - Suma de input + output
  - Base para calcular costo

- [ ] **Costo por Consulta**
  - FÃ³rmula:
    ```
    Costo = (tokens_input * precio_input / 1M) +
            (tokens_output * precio_output / 1M)
    ```

#### Usando Callbacks:
```python
from langchain_core.callbacks import get_openai_callback

with get_openai_callback() as cb:
    response = llm.invoke(...)
    print(f"Tokens: {cb.total_tokens}")
    print(f"Costo: ${cb.total_cost}")
```

---

### 2.4 Benchmarking

#### Â¿QuÃ© es?
Comparar diferentes configuraciones para encontrar la Ã³ptima.

#### MÃ©tricas a comparar:
- [ ] **Calidad**
  - PrecisiÃ³n de la respuesta
  - Relevancia
  - Completitud

- [ ] **Costo**
  - $ por consulta
  - ProyecciÃ³n a escala

- [ ] **Velocidad**
  - Tiempo de respuesta
  - Latencia

- [ ] **Tokens**
  - Consumo promedio
  - Variabilidad

#### Proceso:
1. Definir baseline (configuraciÃ³n actual)
2. Crear variantes (diferentes prompts/parÃ¡metros)
3. Ejecutar mismas preguntas en todas
4. Comparar mÃ©tricas
5. Elegir configuraciÃ³n Ã³ptima

---

## ğŸ“‹ PARTE 3: Habilidades TÃ©cnicas

### 3.1 Python
- [ ] Diccionarios y listas
- [ ] Funciones con parÃ¡metros
- [ ] Format strings: `f"Texto {variable}"`
- [ ] Manejo de excepciones bÃ¡sico
- [ ] ImportaciÃ³n de mÃ³dulos

### 3.2 Jupyter Notebooks
- [ ] Ejecutar celdas (Shift + Enter)
- [ ] Reiniciar kernel
- [ ] Ver outputs
- [ ] Exportar notebooks

### 3.3 AnÃ¡lisis de Datos
- [ ] Calcular promedios
- [ ] Comparar valores
- [ ] Calcular porcentajes de mejora
- [ ] Interpretar tablas comparativas

---

## ğŸ“‹ PARTE 4: PreparaciÃ³n PrÃ¡ctica

### 4.1 Verificar Ambiente
```bash
# Comprobar instalaciÃ³n de paquetes
pip list | grep langchain
pip list | grep openai
pip list | grep faiss

# Verificar archivos
ls Clases/Clase\ 1/vectorstore_db/
ls .env
```

### 4.2 Repasar Clase 1
- [ ] Ejecutar el notebook de Clase 1
- [ ] Verificar que el vectorstore existe
- [ ] Hacer 2-3 consultas de prueba
- [ ] Revisar cÃ³mo funciona el retriever

### 4.3 Repasar Clase 2
- [ ] Entender LCEL (operador `|`)
- [ ] Chains bÃ¡sicas vs secuenciales
- [ ] Tools y function calling
- [ ] Output parsers

---

## ğŸ“‹ PARTE 5: Ejercicios de PreparaciÃ³n

### Ejercicio 1: Mejorar un Prompt
Dado este prompt bÃ¡sico:
```
"Responde la pregunta sobre equipos"
```

MejÃ³ralo aplicando:
- [ ] Role playing
- [ ] Instrucciones claras
- [ ] Restricciones
- [ ] Formato de salida

**Respuesta sugerida:**
```
"Eres un especialista tÃ©cnico de Lazarus.
Usa SOLO la informaciÃ³n del contexto para responder.
Si no tienes informaciÃ³n, di 'No tengo esa informaciÃ³n'.
Responde en mÃ¡ximo 3 pÃ¡rrafos, en espaÃ±ol formal."
```

### Ejercicio 2: Calcular Tokens Aproximados
Esta pregunta tiene cuÃ¡ntos tokens aproximadamente:
```
"Â¿CuÃ¡l es el mejor equipo para demoliciÃ³n de concreto pesado?"
```

**Pista:** En espaÃ±ol, 1 token â‰ˆ 1 palabra
**Respuesta:** ~10 tokens

### Ejercicio 3: Calcular Costos
Si una consulta usa:
- Input: 500 tokens
- Output: 150 tokens
- Modelo: gpt-4o-mini ($0.15/$0.60 por 1M tokens)

Â¿CuÃ¡l es el costo?

**Respuesta:**
```
Input: (500 / 1,000,000) * $0.15 = $0.000075
Output: (150 / 1,000,000) * $0.60 = $0.000090
Total: $0.000165
```

### Ejercicio 4: Elegir Temperature
Para cada caso, elige la temperature adecuada:

- [ ] Chatbot de soporte tÃ©cnico â†’ **0.3** (consistencia)
- [ ] Generar ideas de marketing â†’ **0.7-0.9** (creatividad)
- [ ] Clasificar productos â†’ **0.0** (determinismo)
- [ ] Escribir descripciones de productos â†’ **0.5** (balance)

---

## ğŸ“‹ PARTE 6: Glosario de TÃ©rminos

### TÃ©rminos Clave

**Prompt Engineering**
: DiseÃ±o estratÃ©gico de instrucciones para LLMs.

**Temperature**
: ParÃ¡metro que controla aleatoriedad (0=determinista, 1=aleatorio).

**Max Tokens**
: LÃ­mite mÃ¡ximo de tokens en la respuesta del LLM.

**Token**
: Unidad bÃ¡sica de texto (~0.75 palabras en inglÃ©s, ~1 palabra en espaÃ±ol).

**Few-shot Learning**
: Dar ejemplos en el prompt para que el LLM aprenda el formato.

**Chain of Thought (CoT)**
: Pedir al LLM que razone paso a paso.

**Callback**
: FunciÃ³n que se ejecuta durante el proceso para tracking/logging.

**Benchmark**
: ComparaciÃ³n sistemÃ¡tica de diferentes configuraciones.

**Baseline**
: ConfiguraciÃ³n inicial/actual usada como referencia.

**ROI (Return on Investment)**
: Retorno de inversiÃ³n, beneficio vs costo.

---

## ğŸ“‹ PARTE 7: Checklist Final de PreparaciÃ³n

### Antes de la Clase 3:

#### Conocimientos
- [ ] Entiendo quÃ© es RAG y cÃ³mo funciona
- [ ] SÃ© quÃ© son los embeddings y vectorstore
- [ ] Conozco la sintaxis bÃ¡sica de LangChain (LCEL)
- [ ] Entiendo quÃ© es un token
- [ ] SÃ© cÃ³mo se calculan los costos en OpenAI

#### Habilidades
- [ ] Puedo ejecutar un notebook de Jupyter
- [ ] SÃ© usar diccionarios y funciones en Python
- [ ] Puedo interpretar tablas comparativas
- [ ] Entiendo cÃ³mo calcular porcentajes y promedios

#### Ambiente
- [ ] Tengo instalados todos los paquetes necesarios
- [ ] Mi API key de OpenAI funciona
- [ ] Existe el directorio `vectorstore_db/` de Clase 1
- [ ] Puedo abrir y ejecutar notebooks

#### Conceptos Nuevos (Estudiar antes)
- [ ] LeÃ­ sobre Prompt Engineering (15 min)
- [ ] Entiendo quÃ© es temperature (5 min)
- [ ] SÃ© cÃ³mo se miden tokens y costos (10 min)
- [ ] Comprendo el concepto de benchmarking (5 min)

**Total tiempo de estudio: ~35-45 minutos**

---

## ğŸ¯ Plan de Estudio Sugerido

### SesiÃ³n 1 (30 min): Repaso de Fundamentos
1. Re-ejecutar notebook de Clase 1 (15 min)
2. Repasar conceptos de RAG (10 min)
3. Verificar ambiente tÃ©cnico (5 min)

### SesiÃ³n 2 (45 min): Conceptos Nuevos
1. Leer sobre Prompt Engineering (20 min)
   - OpenAI Best Practices
   - Ejemplos de Few-shot y CoT
2. Estudiar parÃ¡metros del LLM (15 min)
   - Temperature
   - Max Tokens
3. Entender mediciÃ³n de costos (10 min)
   - Precios de OpenAI
   - CÃ¡lculo de tokens

### SesiÃ³n 3 (30 min): PrÃ¡ctica
1. Hacer ejercicios de preparaciÃ³n (20 min)
2. Escribir 3 prompts diferentes (10 min)
   - Uno simple
   - Uno con instrucciones
   - Uno con Few-shot

**Total: ~2 horas de preparaciÃ³n**

---

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n Oficial
- [OpenAI Pricing](https://openai.com/pricing)
- [OpenAI API Docs](https://platform.openai.com/docs)
- [LangChain Docs](https://python.langchain.com/docs/get_started/introduction)

### ArtÃ­culos y Tutoriales
- [Prompt Engineering Guide](https://www.promptingguide.ai/)
- [Learn Prompting](https://learnprompting.org/)
- [Chain of Thought Paper](https://arxiv.org/abs/2201.11903)

### Videos (Opcional)
- Buscar en YouTube: "Prompt Engineering Tutorial"
- Buscar: "LangChain Temperature Explained"
- Buscar: "OpenAI Cost Optimization"

---

## â“ Preguntas Frecuentes

### Â¿CuÃ¡nto tiempo me tomarÃ¡ la Clase 3?
- EjecuciÃ³n del notebook: 45-60 min
- AnÃ¡lisis y aprendizaje: 30-45 min
- **Total: ~2 horas**

### Â¿Necesito la Clase 2 completada?
No es estrictamente necesaria, pero ayuda entender mejor LCEL y chains.

### Â¿CuÃ¡nto costarÃ¡ ejecutar los ejercicios?
- Ejercicio 1: ~$0.002 (3 prompts Ã— 1 pregunta)
- Ejercicio 2: ~$0.003 (3 configs Ã— 1 pregunta)
- Ejercicio 3: ~$0.005 (5 preguntas)
- **Total: ~$0.01 (1 centavo de dÃ³lar)**

### Â¿QuÃ© pasa si no tengo el vectorstore de Clase 1?
Puedes crearlo ejecutando solo las primeras celdas del notebook de Clase 1.

### Â¿Puedo usar otro modelo que no sea gpt-4o-mini?
SÃ­, pero los costos variarÃ¡n. gpt-4o-mini es el mÃ¡s econÃ³mico.

---

## âœ… Auto-EvaluaciÃ³n

Antes de comenzar la Clase 3, verifica que puedas responder SÃ a:

1. Â¿Entiendo quÃ© es RAG? â†’ [ ]
2. Â¿SÃ© quÃ© es un token? â†’ [ ]
3. Â¿Puedo escribir un prompt bÃ¡sico? â†’ [ ]
4. Â¿Entiendo quÃ© es temperature? â†’ [ ]
5. Â¿SÃ© cÃ³mo se calculan costos en OpenAI? â†’ [ ]
6. Â¿Tengo el ambiente tÃ©cnico listo? â†’ [ ]
7. Â¿He repasado los conceptos de Clase 1? â†’ [ ]

**Si respondiste SÃ a 6 o mÃ¡s, estÃ¡s listo para la Clase 3! ğŸš€**

---

**Â¡Mucho Ã©xito en tu aprendizaje! ğŸ“š**

*Esta guÃ­a fue diseÃ±ada para que te prepares efectivamente en ~2 horas.*
