# ğŸš€ Clase 3: OptimizaciÃ³n de Agentes RAG (Semana 2)

## ğŸ“‹ DescripciÃ³n

En esta clase aprenderÃ¡s a **optimizar** tu agente RAG, llevÃ¡ndolo de un prototipo funcional a un sistema listo para producciÃ³n. El enfoque estÃ¡ en:

- **Prompt Engineering**: DiseÃ±ar prompts efectivos
- **Ajuste de ParÃ¡metros**: Optimizar temperature y max_tokens
- **MediciÃ³n de Costos**: Trackear y reducir costos operativos

## ğŸ¯ Objetivos de Aprendizaje

Al finalizar esta clase, serÃ¡s capaz de:

1. âœ… Comparar diferentes estrategias de prompts (Minimal, EstÃ¡ndar, Profesional)
2. âœ… Aplicar tÃ©cnicas de Few-shot Learning y Chain of Thought
3. âœ… Ajustar parÃ¡metros del LLM para balancear calidad/costo
4. âœ… Medir tokens y costos en tiempo real con callbacks
5. âœ… Crear benchmarks para comparar mejoras
6. âœ… Tomar decisiones basadas en datos

## ğŸ“š Contenido

### 1. Setup Inicial
- ConfiguraciÃ³n del ambiente
- Carga del vectorstore de Clase 1 (sin recrear embeddings)

### 2. Prompt Engineering
- **Prompt Minimal**: Instrucciones bÃ¡sicas
- **Prompt EstÃ¡ndar**: Como Clase 1
- **Prompt Profesional**: Few-shot + Chain of Thought

### 3. MediciÃ³n y ComparaciÃ³n
- FunciÃ³n para trackear: tiempo, tokens, costos
- Comparativa de 3 prompts diferentes
- AnÃ¡lisis de resultados

### 4. OptimizaciÃ³n de ParÃ¡metros
- ConfiguraciÃ³n A: RÃ¡pido y barato (temp=0.3, tokens=200)
- ConfiguraciÃ³n B: Balanceado (temp=0.5, tokens=300)
- ConfiguraciÃ³n C: Creativo (temp=0.7, tokens=400)

### 5. AnÃ¡lisis de Costos
- Costo promedio por consulta
- ProyecciÃ³n para 100 y 1000 consultas
- ROI de las optimizaciones

### 6. Benchmark Final
- ComparaciÃ³n Semana 1 vs Semana 2
- MÃ©tricas de mejora
- Recomendaciones

## ğŸ› ï¸ Requisitos Previos

### Conocimientos
- âœ… Haber completado [Clase 1](../Clase%201/) - RAG bÃ¡sico
- âœ… Entender conceptos de vectorstore y embeddings
- âœ… Familiaridad con LangChain

### Archivos necesarios
- âœ… `vectorstore_db/` - Creado en Clase 1
- âœ… Archivo `.env` con `OPENAI_API_KEY`

### Dependencias
```bash
pip install openai python-dotenv langchain langchain-openai langchain-community pypdf faiss-cpu
```

## ğŸ“‚ Archivos en esta carpeta

```
Clase 3/
â”œâ”€â”€ README.md                          # Este archivo
â”œâ”€â”€ Semana_2_Optimizacion_RAG.ipynb   # Notebook principal
â””â”€â”€ Catalogo_Equipos_Construccion.pdf  # PDF del catÃ¡logo
```

## ğŸš€ CÃ³mo usar este material

### Paso 1: Verificar requisitos
```bash
# AsegÃºrate de tener el vectorstore de Clase 1
ls ../Clase\ 1/vectorstore_db/
```

### Paso 2: Abrir el notebook
```bash
jupyter notebook Semana_2_Optimizacion_RAG.ipynb
```

### Paso 3: Ejecutar celda por celda
- Lee las explicaciones en cada celda
- Ejecuta el cÃ³digo
- Analiza los resultados
- Experimenta con diferentes configuraciones

## ğŸ“Š Conceptos Clave

### 1. Prompt Engineering

**Â¿QuÃ© es?**
El arte de diseÃ±ar instrucciones efectivas para el LLM.

**TÃ©cnicas:**
- **Few-shot Learning**: Incluir ejemplos en el prompt
- **Chain of Thought**: Pedir razonamiento paso a paso
- **Role Playing**: Asignar un rol especÃ­fico al LLM

### 2. ParÃ¡metros del LLM

**Temperature (0-1):**
- `0.0`: Determinista, siempre la misma respuesta
- `0.3`: Consistente, ideal para atenciÃ³n al cliente
- `0.7`: Creativo, para generaciÃ³n de contenido
- `1.0`: Muy aleatorio, experimental

**Max Tokens:**
- LÃ­mite de longitud de respuesta
- MÃ¡s tokens = Mayor costo
- Ajustar segÃºn necesidad real

### 3. Cost Tracking

**MÃ©tricas importantes:**
- **Tokens de prompt**: Lo que envÃ­as al LLM
- **Tokens de completion**: Lo que el LLM genera
- **Tokens totales**: Suma de ambos
- **Costo por consulta**: VarÃ­a segÃºn modelo

**Precios aproximados (gpt-4o-mini):**
- Input: $0.15 / 1M tokens
- Output: $0.60 / 1M tokens

## ğŸ“ Ejercicios

### Ejercicio 1: Comparar Prompts
Ejecuta la misma pregunta con 3 prompts diferentes y compara:
- Calidad de la respuesta
- Tokens consumidos
- Costo
- Tiempo de respuesta

### Ejercicio 2: Ajustar ParÃ¡metros
Prueba diferentes configuraciones de temperature y max_tokens:
- Â¿CuÃ¡l da mejores respuestas?
- Â¿CuÃ¡l es mÃ¡s econÃ³mica?
- Â¿CuÃ¡l es el mejor balance?

### Ejercicio 3: Calcular ROI
Mide el ahorro logrado con las optimizaciones:
- Costo Semana 1 vs Semana 2
- Ahorro en 1000 consultas
- Mejora en satisfacciÃ³n del usuario

## ğŸ’¡ Tips y Mejores PrÃ¡cticas

### Para Prompts:
1. **SÃ© especÃ­fico**: Instrucciones claras = mejores resultados
2. **Usa ejemplos**: Few-shot learning mejora la calidad
3. **Pide paso a paso**: Chain of Thought para razonamientos
4. **Define el rol**: "Eres un experto en..." funciona bien
5. **Limita la respuesta**: "MÃ¡ximo 3 pÃ¡rrafos" controla longitud

### Para ParÃ¡metros:
1. **Empieza con temperature=0.3**: Para aplicaciones de producciÃ³n
2. **Ajusta max_tokens**: Solo lo necesario, no mÃ¡s
3. **Mide siempre**: Usa callbacks para trackear costos
4. **Prueba iterativamente**: PequeÃ±os cambios, grandes efectos
5. **Documenta**: Guarda las configuraciones que funcionan

### Para Costos:
1. **Usa gpt-4o-mini**: MÃ¡s barato que gpt-4
2. **Optimiza chunks**: Menos contexto = menos tokens
3. **Cachea cuando puedas**: Evita consultas repetidas
4. **Monitorea en producciÃ³n**: Costos pueden escalar rÃ¡pido
5. **Establece lÃ­mites**: Budget alerts en OpenAI

## ğŸ” Resultados Esperados

DespuÃ©s de las optimizaciones, deberÃ­as lograr:

- âœ… **20-40% reducciÃ³n** en tokens consumidos
- âœ… **15-30% reducciÃ³n** en costos por consulta
- âœ… **10-20% mejora** en tiempo de respuesta
- âœ… **Mejor calidad** en respuestas (mÃ¡s especÃ­ficas, mejor estructuradas)

## ğŸ“ˆ ComparaciÃ³n: Antes vs DespuÃ©s

### Antes (Semana 1 - Sin optimizar)
```
Costo/consulta: $0.0008
Tokens/consulta: 850
Tiempo: 2.5s
Calidad: 70/100
```

### DespuÃ©s (Semana 2 - Optimizado)
```
Costo/consulta: $0.0005
Tokens/consulta: 600
Tiempo: 1.8s
Calidad: 95/100
```

### Mejora
```
Ahorro de costo: 37.5%
Ahorro de tokens: 29.4%
ReducciÃ³n de tiempo: 28%
Mejora de calidad: +25 puntos
```

## ğŸš€ PrÃ³ximos Pasos

1. **Implementa en producciÃ³n**: Usa la configuraciÃ³n Ã³ptima
2. **Recopila feedback real**: Los usuarios te dirÃ¡n quÃ© funciona
3. **Itera continuamente**: Las mejoras son un proceso constante
4. **PrepÃ¡rate para Clase 4**: TÃ©cnicas avanzadas de RAG

## ğŸ“š Recursos Adicionales

### DocumentaciÃ³n
- [OpenAI Pricing](https://openai.com/pricing)
- [LangChain Callbacks](https://python.langchain.com/docs/modules/callbacks/)
- [Prompt Engineering Guide](https://www.promptingguide.ai/)

### ArtÃ­culos recomendados
- [Best practices for prompt engineering](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api)
- [Chain of Thought Prompting](https://arxiv.org/abs/2201.11903)
- [Few-shot Learning](https://arxiv.org/abs/2005.14165)

### Comunidad
- [LangChain Discord](https://discord.gg/langchain)
- [OpenAI Community Forum](https://community.openai.com/)

## âš ï¸ SoluciÃ³n de Problemas

### Error: "No se encontrÃ³ vectorstore_db"
**SoluciÃ³n:** Ejecuta primero el notebook de Clase 1 para crear el vectorstore.

### Error: "API key invÃ¡lida"
**SoluciÃ³n:** Verifica que tu archivo `.env` tenga `OPENAI_API_KEY=sk-...`

### Los costos son muy altos
**SoluciÃ³n:** Reduce max_tokens, usa temperature mÃ¡s bajo, optimiza el prompt.

### Las respuestas son muy cortas
**SoluciÃ³n:** Aumenta max_tokens, ajusta el prompt para pedir mÃ¡s detalle.

### Las respuestas son inconsistentes
**SoluciÃ³n:** Baja la temperature (prueba con 0.3 o menos).

## ğŸ¯ Checklist de Completitud

Marca lo que has logrado:

- [ ] Entiendo quÃ© es prompt engineering
- [ ] Puedo comparar diferentes prompts
- [ ] SÃ© ajustar temperature y max_tokens
- [ ] Puedo trackear costos con callbacks
- [ ] Entiendo cÃ³mo calcular ROI
- [ ] He creado mi propio benchmark
- [ ] IdentifiquÃ© la configuraciÃ³n Ã³ptima
- [ ] DocumentÃ© mis hallazgos
- [ ] Estoy listo para Clase 4

---

**Â¡Ã‰xito en tu optimizaciÃ³n de agentes RAG! ğŸ“**

*Â¿Preguntas? Revisa la documentaciÃ³n o consulta con tu instructor.*
