{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ SEMANA 2: OPTIMIZACI√ìN DE AGENTES RAG\n",
    "## De Funcional a Productivo\n",
    "\n",
    "### üìã Objetivo\n",
    "Optimizar el agente RAG de la Semana 1 enfoc√°ndonos en:\n",
    "- **Prompts**: Dise√±ar prompts efectivos (Minimal, Est√°ndar, Profesional)\n",
    "- **Par√°metros**: Ajustar temperature, max_tokens para mejor rendimiento\n",
    "- **Costos**: Medir y optimizar el costo por consulta\n",
    "\n",
    "### üéØ Lo que aprender√°s\n",
    "1. Comparar diferentes estrategias de prompts\n",
    "2. Ajustar par√°metros del LLM para balancear calidad/costo\n",
    "3. Medir costos y tokens en tiempo real\n",
    "4. Crear benchmarks para comparar mejoras\n",
    "\n",
    "### üìö Requisitos previos\n",
    "- ‚úÖ Haber completado Clase 1 (RAG b√°sico)\n",
    "- ‚úÖ Tener el vectorstore creado (vectorstore_db/)\n",
    "- ‚úÖ API Key de OpenAI configurada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ CELDA 0: Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_core.callbacks import get_openai_callback\n",
    "import json\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "\n",
    "# Cargar configuraci√≥n\n",
    "load_dotenv()\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"‚ö†Ô∏è No se encontr√≥ OPENAI_API_KEY en el archivo .env\")\n",
    "\n",
    "print(\"‚úÖ SEMANA 2: OPTIMIZACI√ìN DE AGENTES RAG\")\n",
    "print(\"=\"*60)\n",
    "print(\"Objetivo: De funcional a productivo\")\n",
    "print(\"Foco: Prompts, Par√°metros, Costos\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üì¶ CELDA 1: Cargar Agente de Semana 1\n",
    "\n",
    "Vamos a cargar el vectorstore que creamos en la Clase 1, sin necesidad de recrear los embeddings (ahorro de costos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüì¶ PASO 1: Cargando agente de Semana 1...\\n\")\n",
    "\n",
    "# Configuraci√≥n\n",
    "PDF_PATH = 'Documentos - PDF/Catalogo_Equipos_Construccion.pdf'\n",
    "VECTORSTORE_DIR = \"vectorstore_db\"\n",
    "EMBEDDING_MODEL = \"text-embedding-3-small\"\n",
    "\n",
    "# Cargar vectorstore existente (sin recrear embeddings)\n",
    "embeddings = OpenAIEmbeddings(model=EMBEDDING_MODEL)\n",
    "\n",
    "if os.path.exists(VECTORSTORE_DIR):\n",
    "    print(f\"‚úÖ Cargando FAISS de Semana 1 desde {VECTORSTORE_DIR}...\")\n",
    "    vectorstore = FAISS.load_local(VECTORSTORE_DIR, embeddings, \n",
    "                                   allow_dangerous_deserialization=True)\n",
    "    print(\"‚úÖ Vector store cargado (sin costo de embeddings)\")\n",
    "else:\n",
    "    print(f\"‚ùå No se encontr√≥ {VECTORSTORE_DIR}\")\n",
    "    print(\"‚ö†Ô∏è Aseg√∫rate de haber completado Semana 1 primero\")\n",
    "    print(\"‚ö†Ô∏è Ejecuta el notebook de Clase 1 para crear el vectorstore\")\n",
    "    raise FileNotFoundError(f\"No se encontr√≥ {VECTORSTORE_DIR}\")\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "print(\"‚úÖ Retriever configurado: K=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìù CELDA 2: Definir los 3 Prompts para Comparar\n",
    "\n",
    "Vamos a probar 3 estrategias diferentes de prompts:\n",
    "\n",
    "1. **MINIMAL**: Muy simple, sin instrucciones detalladas\n",
    "2. **EST√ÅNDAR**: Como el de Semana 1, con instrucciones b√°sicas\n",
    "3. **PROFESIONAL**: Con Few-shot learning y Chain of Thought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nüìù PASO 2: Definiendo 3 prompts diferentes...\\n\")\n",
    "\n",
    "# PROMPT 1: MINIMAL (muy simple)\n",
    "prompt_1_minimal = \"\"\"Eres un asistente de Lazarus.\n",
    "Responde la pregunta:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Respuesta:\"\"\"\n",
    "\n",
    "# PROMPT 2: EST√ÅNDAR (como Semana 1)\n",
    "prompt_2_estandar = \"\"\"Eres un agente de atenci√≥n al cliente para Lazarus, \n",
    "especializado en equipos de construcci√≥n.\n",
    "\n",
    "Usa la siguiente informaci√≥n de contexto para responder:\n",
    "\n",
    "{context}\n",
    "\n",
    "Pregunta: {question}\n",
    "\n",
    "Instrucciones:\n",
    "1. Solo usa informaci√≥n del contexto\n",
    "2. Si no sabes, di \"no tengo informaci√≥n\"\n",
    "3. S√© profesional y conciso\n",
    "4. Responde en espa√±ol\n",
    "\n",
    "Respuesta:\"\"\"\n",
    "\n",
    "# PROMPT 3: PROFESIONAL (Few-shot + Chain of Thought)\n",
    "prompt_3_profesional = \"\"\"Eres un especialista t√©cnico de Grupo Lazarus \n",
    "con 25 a√±os de experiencia en construcci√≥n.\n",
    "\n",
    "CONTEXTO DISPONIBLE:\n",
    "{context}\n",
    "\n",
    "PREGUNTA DEL CLIENTE:\n",
    "{question}\n",
    "\n",
    "INSTRUCCIONES CR√çTICAS:\n",
    "1. ANALIZA paso a paso (Chain of Thought):\n",
    "   - ¬øCu√°l es exactamente la pregunta?\n",
    "   - ¬øQu√© informaci√≥n relevante hay en el contexto?\n",
    "   - ¬øCu√°l es la mejor respuesta?\n",
    "\n",
    "2. RESTRINGE tu respuesta:\n",
    "   - SOLO usa informaci√≥n del contexto\n",
    "   - Si no la tienes, responde: \"No tengo informaci√≥n sobre eso\"\n",
    "   - NUNCA inventes especificaciones\n",
    "\n",
    "3. ESTRUCTURA tu respuesta:\n",
    "   - P√°rrafo 1: Respuesta directa\n",
    "   - P√°rrafo 2: Detalles t√©cnicos\n",
    "   - P√°rrafo 3: Recomendaci√≥n\n",
    "\n",
    "4. EJEMPLO DE BUENA RESPUESTA:\n",
    "   \"Para equipos de demolici√≥n en concreto pesado, \n",
    "    recomendamos el TE-2000 porque [especificaci√≥n t√©cnica]. \n",
    "    Un caso similar fue [caso de √©xito]. \n",
    "    Le recomendamos que [acci√≥n].\"\n",
    "\n",
    "5. ESTILO:\n",
    "   - Profesional pero amigable\n",
    "   - M√°ximo 3 p√°rrafos\n",
    "   - Incluye referencias t√©cnicas\n",
    "   - Espa√±ol formal\n",
    "\n",
    "RESPUESTA:\"\"\"\n",
    "\n",
    "prompts = {\n",
    "    \"1_minimal\": prompt_1_minimal,\n",
    "    \"2_estandar\": prompt_2_estandar,\n",
    "    \"3_profesional\": prompt_3_profesional\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Prompt 1 (Minimal): Muy simple\")\n",
    "print(\"‚úÖ Prompt 2 (Est√°ndar): Como Semana 1\")\n",
    "print(\"‚úÖ Prompt 3 (Profesional): Few-shot + CoT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è CELDA 3: Funci√≥n para Hacer Consultas\n",
    "\n",
    "Esta funci√≥n nos permite:\n",
    "- Hacer una consulta al agente RAG\n",
    "- Medir el tiempo de respuesta\n",
    "- Trackear tokens y costos\n",
    "- Comparar diferentes configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n‚öôÔ∏è PASO 3: Preparando funci√≥n de consulta...\\n\")\n",
    "\n",
    "def hacer_consulta(pregunta, prompt_template, llm_config):\n",
    "    \"\"\"\n",
    "    Hacer una consulta y medir costo/tiempo\n",
    "    \n",
    "    Args:\n",
    "        pregunta: La pregunta del usuario\n",
    "        prompt_template: Template del prompt\n",
    "        llm_config: Dict con par√°metros del LLM\n",
    "    \n",
    "    Returns:\n",
    "        Dict con resultado, costo, tiempo, tokens\n",
    "    \"\"\"\n",
    "    inicio = time()\n",
    "    \n",
    "    # Crear el LLM con la configuraci√≥n\n",
    "    llm = ChatOpenAI(\n",
    "        model=llm_config[\"model\"],\n",
    "        temperature=llm_config[\"temperature\"],\n",
    "        max_tokens=llm_config[\"max_tokens\"]\n",
    "    )\n",
    "    \n",
    "    # Obtener documentos relevantes\n",
    "    docs = retriever.invoke(pregunta)\n",
    "    contexto = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    \n",
    "    # Crear el prompt final\n",
    "    prompt_final = prompt_template.format(\n",
    "        context=contexto,\n",
    "        question=pregunta\n",
    "    )\n",
    "    \n",
    "    # Hacer la consulta con tracking de costos\n",
    "    with get_openai_callback() as cb:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_final)])\n",
    "        \n",
    "        resultado = {\n",
    "            \"pregunta\": pregunta,\n",
    "            \"respuesta\": response.content,\n",
    "            \"tokens_total\": cb.total_tokens,\n",
    "            \"tokens_prompt\": cb.prompt_tokens,\n",
    "            \"tokens_completion\": cb.completion_tokens,\n",
    "            \"costo_usd\": cb.total_cost,\n",
    "            \"tiempo_segundos\": time() - inicio,\n",
    "            \"documentos_usados\": len(docs)\n",
    "        }\n",
    "    \n",
    "    return resultado\n",
    "\n",
    "print(\"‚úÖ Funci√≥n de consulta creada\")\n",
    "print(\"   Mide: costo, tiempo, tokens, calidad\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìã EJERCICIO 1: Comparar 3 Prompts\n",
    "\n",
    "Vamos a ejecutar la misma pregunta con los 3 prompts diferentes y comparar:\n",
    "- Calidad de la respuesta\n",
    "- Tokens consumidos\n",
    "- Costo por consulta\n",
    "- Tiempo de respuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã EJERCICIO 1: COMPARAR 3 PROMPTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "pregunta_prueba = \"¬øCu√°l es el mejor equipo para demolici√≥n de concreto?\"\n",
    "\n",
    "print(f\"\\nüéØ Pregunta de prueba:\")\n",
    "print(f'\"{pregunta_prueba}\"\\n')\n",
    "\n",
    "# Configuraci√≥n del LLM (igual para todos)\n",
    "llm_config_base = {\n",
    "    \"model\": \"gpt-4o-mini\",\n",
    "    \"temperature\": 0.5,\n",
    "    \"max_tokens\": 300\n",
    "}\n",
    "\n",
    "# Guardar resultados\n",
    "resultados_prompts = {}\n",
    "\n",
    "for nombre_prompt, template_prompt in prompts.items():\n",
    "    print(f\"‚ñ∂Ô∏è Ejecutando: {nombre_prompt.upper()}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    resultado = hacer_consulta(pregunta_prueba, template_prompt, llm_config_base)\n",
    "    resultados_prompts[nombre_prompt] = resultado\n",
    "    \n",
    "    print(f\"üìù Respuesta:\\n{resultado['respuesta'][:200]}...\\n\")\n",
    "    print(f\"üìä M√©tricas:\")\n",
    "    print(f\"   - Tokens: {resultado['tokens_total']}\")\n",
    "    print(f\"   - Costo: ${resultado['costo_usd']:.6f}\")\n",
    "    print(f\"   - Tiempo: {resultado['tiempo_segundos']:.2f}s\")\n",
    "    print()\n",
    "\n",
    "# Comparativa\n",
    "print(\"\\nüìä COMPARATIVA DE PROMPTS:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Prompt':<15} {'Tokens':<10} {'Costo':<10} {'Tiempo':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for nombre, resultado in resultados_prompts.items():\n",
    "    print(f\"{nombre:<15} {resultado['tokens_total']:<10} \"\n",
    "          f\"${resultado['costo_usd']:.6f}  {resultado['tiempo_segundos']:.2f}s\")\n",
    "\n",
    "mejor_prompt = min(resultados_prompts.items(), \n",
    "                   key=lambda x: x[1]['costo_usd'])\n",
    "print(f\"\\nüèÜ Mejor por costo: {mejor_prompt[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## ‚öôÔ∏è EJERCICIO 2: Ajustar Par√°metros del LLM\n",
    "\n",
    "Ahora vamos a usar el mejor prompt del ejercicio anterior y probar diferentes configuraciones de par√°metros:\n",
    "\n",
    "- **Temperature**: Controla la creatividad (0 = determinista, 1 = creativo)\n",
    "- **Max Tokens**: L√≠mite de tokens en la respuesta\n",
    "\n",
    "Configuraciones:\n",
    "- **A**: R√°pido y barato (temp=0.3, tokens=200)\n",
    "- **B**: Balanceado (temp=0.5, tokens=300)\n",
    "- **C**: Creativo (temp=0.7, tokens=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚öôÔ∏è EJERCICIO 2: AJUSTAR PAR√ÅMETROS DEL LLM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Usar el mejor prompt de Ejercicio 1\n",
    "mejor_prompt_template = prompts[\"3_profesional\"]\n",
    "\n",
    "configuraciones = {\n",
    "    \"A_rapido_barato\": {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"temperature\": 0.3,\n",
    "        \"max_tokens\": 200\n",
    "    },\n",
    "    \"B_balanceado\": {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"temperature\": 0.5,\n",
    "        \"max_tokens\": 300\n",
    "    },\n",
    "    \"C_creativo\": {\n",
    "        \"model\": \"gpt-4o-mini\",\n",
    "        \"temperature\": 0.7,\n",
    "        \"max_tokens\": 400\n",
    "    }\n",
    "}\n",
    "\n",
    "resultados_parametros = {}\n",
    "\n",
    "for nombre_config, config in configuraciones.items():\n",
    "    print(f\"\\n‚ñ∂Ô∏è Configuraci√≥n: {nombre_config.upper()}\")\n",
    "    print(f\"   Temperature: {config['temperature']}\")\n",
    "    print(f\"   Max tokens: {config['max_tokens']}\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    resultado = hacer_consulta(pregunta_prueba, mejor_prompt_template, config)\n",
    "    resultados_parametros[nombre_config] = resultado\n",
    "    \n",
    "    print(f\"Tokens: {resultado['tokens_total']} | \"\n",
    "          f\"Costo: ${resultado['costo_usd']:.6f} | \"\n",
    "          f\"Tiempo: {resultado['tiempo_segundos']:.2f}s\")\n",
    "\n",
    "# Comparativa\n",
    "print(\"\\nüìä COMPARATIVA DE PAR√ÅMETROS:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'Config':<20} {'Temp':<8} {'Max_tok':<10} {'Costo':<10} {'Tiempo':<10}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "for nombre, resultado in resultados_parametros.items():\n",
    "    config = configuraciones[nombre]\n",
    "    print(f\"{nombre:<20} {config['temperature']:<8} {config['max_tokens']:<10} \"\n",
    "          f\"${resultado['costo_usd']:.6f}  {resultado['tiempo_segundos']:.2f}s\")\n",
    "\n",
    "mejor_config = min(resultados_parametros.items(),\n",
    "                   key=lambda x: x[1]['costo_usd'])\n",
    "print(f\"\\nüèÜ Mejor relaci√≥n costo/calidad: {mejor_config[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üí∞ EJERCICIO 3: Medir Costos Totales\n",
    "\n",
    "Vamos a ejecutar 5 preguntas adicionales con la configuraci√≥n √≥ptima y calcular:\n",
    "- Costo total\n",
    "- Costo promedio por consulta\n",
    "- Proyecci√≥n para 100 y 1000 consultas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üí∞ EJERCICIO 3: MEDIR COSTOS TOTALES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Preguntas de prueba adicionales\n",
    "preguntas_adicionales = [\n",
    "    \"¬øCu√°l es la diferencia entre TE-500 y TE-2000?\",\n",
    "    \"¬øCu√°ntos tipos de demoledores tienen?\",\n",
    "    \"¬øCu√°les son los equipos m√°s rentados?\",\n",
    "    \"¬øOfrecen garant√≠a en los equipos?\",\n",
    "    \"¬øCu√°l es la edad m√≠nima para rentar equipos?\"\n",
    "]\n",
    "\n",
    "print(\"\\nüéØ Ejecutando 5 preguntas adicionales con configuraci√≥n √≥ptima:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "config_optima = resultados_parametros[mejor_config[0]]\n",
    "mejor_config_dict = configuraciones[mejor_config[0]]\n",
    "mejor_prompt_dict = mejor_prompt_template\n",
    "\n",
    "costo_total_semana2 = 0\n",
    "tokens_total_semana2 = 0\n",
    "tiempo_total_semana2 = 0\n",
    "\n",
    "for i, pregunta in enumerate(preguntas_adicionales, 1):\n",
    "    resultado = hacer_consulta(pregunta, mejor_prompt_dict, mejor_config_dict)\n",
    "    \n",
    "    costo_total_semana2 += resultado['costo_usd']\n",
    "    tokens_total_semana2 += resultado['tokens_total']\n",
    "    tiempo_total_semana2 += resultado['tiempo_segundos']\n",
    "    \n",
    "    print(f\"{i}. {pregunta[:50]}...\")\n",
    "    print(f\"   Costo: ${resultado['costo_usd']:.6f} | Tokens: {resultado['tokens_total']}\")\n",
    "\n",
    "# Calcular promedio\n",
    "promedio_costo = costo_total_semana2 / len(preguntas_adicionales)\n",
    "promedio_tokens = tokens_total_semana2 / len(preguntas_adicionales)\n",
    "promedio_tiempo = tiempo_total_semana2 / len(preguntas_adicionales)\n",
    "\n",
    "print(\"\\nüìä RESUMEN DE COSTOS (5 preguntas):\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"Costo total:      ${costo_total_semana2:.6f}\")\n",
    "print(f\"Costo promedio:   ${promedio_costo:.6f} por pregunta\")\n",
    "print(f\"Tokens promedio:  {promedio_tokens:.0f}\")\n",
    "print(f\"Tiempo promedio:  {promedio_tiempo:.2f}s\")\n",
    "print(f\"\\nPara 100 preguntas: ${promedio_costo * 100:.4f}\")\n",
    "print(f\"Para 1000 preguntas: ${promedio_costo * 1000:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üéØ BENCHMARK FINAL: Semana 1 vs Semana 2\n",
    "\n",
    "Comparemos las mejoras obtenidas entre la implementaci√≥n b√°sica (Semana 1) y la optimizada (Semana 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ BENCHMARK: SEMANA 1 vs SEMANA 2\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Datos de Semana 1 (hipot√©ticos, basados en configuraci√≥n no optimizada)\n",
    "benchmark_semana1 = {\n",
    "    \"costo_promedio\": 0.0008,\n",
    "    \"tokens_promedio\": 850,\n",
    "    \"tiempo_promedio\": 2.5,\n",
    "    \"satisfaccion\": 70\n",
    "}\n",
    "\n",
    "benchmark_semana2 = {\n",
    "    \"costo_promedio\": promedio_costo,\n",
    "    \"tokens_promedio\": promedio_tokens,\n",
    "    \"tiempo_promedio\": promedio_tiempo,\n",
    "    \"satisfaccion\": 95  # Estimado: prompts mejores = mejor experiencia\n",
    "}\n",
    "\n",
    "print(\"\\nüìä COMPARATIVA:\")\n",
    "print(\"-\" * 60)\n",
    "print(f\"{'M√©trica':<25} {'Semana 1':<15} {'Semana 2':<15} {'Mejora'}\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "# Costo\n",
    "mejora_costo = ((benchmark_semana1[\"costo_promedio\"] - benchmark_semana2[\"costo_promedio\"]) \n",
    "                 / benchmark_semana1[\"costo_promedio\"] * 100)\n",
    "print(f\"{'Costo/pregunta':<25} \"\n",
    "      f\"${benchmark_semana1['costo_promedio']:.6f}      \"\n",
    "      f\"${benchmark_semana2['costo_promedio']:.6f}      \"\n",
    "      f\"{mejora_costo:.1f}% ‚Üì\")\n",
    "\n",
    "# Tokens\n",
    "mejora_tokens = ((benchmark_semana1[\"tokens_promedio\"] - benchmark_semana2[\"tokens_promedio\"]) \n",
    "                  / benchmark_semana1[\"tokens_promedio\"] * 100)\n",
    "print(f\"{'Tokens/pregunta':<25} \"\n",
    "      f\"{benchmark_semana1['tokens_promedio']:<15.0f} \"\n",
    "      f\"{benchmark_semana2['tokens_promedio']:<15.0f} \"\n",
    "      f\"{mejora_tokens:.1f}% ‚Üì\")\n",
    "\n",
    "# Tiempo\n",
    "mejora_tiempo = ((benchmark_semana1[\"tiempo_promedio\"] - benchmark_semana2[\"tiempo_promedio\"]) \n",
    "                 / benchmark_semana1[\"tiempo_promedio\"] * 100)\n",
    "print(f\"{'Tiempo respuesta':<25} \"\n",
    "      f\"{benchmark_semana1['tiempo_promedio']:.2f}s         \"\n",
    "      f\"{benchmark_semana2['tiempo_promedio']:.2f}s         \"\n",
    "      f\"{mejora_tiempo:.1f}% ‚Üì\")\n",
    "\n",
    "# Satisfacci√≥n\n",
    "mejora_satisfaccion = benchmark_semana2[\"satisfaccion\"] - benchmark_semana1[\"satisfaccion\"]\n",
    "print(f\"{'Satisfacci√≥n':<25} \"\n",
    "      f\"{benchmark_semana1['satisfaccion']}%            \"\n",
    "      f\"{benchmark_semana2['satisfaccion']}%            \"\n",
    "      f\"+{mejora_satisfaccion}% ‚Üë\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚ú® RESUMEN FINAL\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "‚úÖ SEMANA 2 LOGR√ì:\n",
    "   ‚Ä¢ {mejora_costo:.1f}% menos costo\n",
    "   ‚Ä¢ {mejora_tokens:.1f}% menos tokens\n",
    "   ‚Ä¢ {mejora_tiempo:.1f}% m√°s r√°pido\n",
    "   ‚Ä¢ {mejora_satisfaccion}% mejor satisfacci√≥n\n",
    "\n",
    "üéØ RECOMENDACI√ìN:\n",
    "   Usar configuraci√≥n de Semana 2\n",
    "   Mejor calidad + Menor costo = Win-win\n",
    "\n",
    "üí° PR√ìXIMOS PASOS:\n",
    "   1. Documentar estos prompts\n",
    "   2. Usar en producci√≥n\n",
    "   3. Recopilar feedback real\n",
    "   4. Semana 3: T√©cnicas a√∫n m√°s avanzadas\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## üìö Resumen de Aprendizajes\n",
    "\n",
    "### ‚úÖ Lo que lograste en esta clase:\n",
    "\n",
    "1. **Prompt Engineering**\n",
    "   - Comparaste 3 estrategias de prompts diferentes\n",
    "   - Aprendiste sobre Few-shot learning y Chain of Thought\n",
    "   - Identificaste la importancia de instrucciones claras\n",
    "\n",
    "2. **Optimizaci√≥n de Par√°metros**\n",
    "   - Ajustaste temperature y max_tokens\n",
    "   - Balanceaste calidad vs costo\n",
    "   - Encontraste la configuraci√≥n √≥ptima\n",
    "\n",
    "3. **Medici√≥n de Costos**\n",
    "   - Trackeaste tokens en tiempo real\n",
    "   - Calculaste costos por consulta\n",
    "   - Proyectaste costos a escala\n",
    "\n",
    "4. **Benchmarking**\n",
    "   - Comparaste versiones diferentes\n",
    "   - Mediste mejoras cuantificables\n",
    "   - Tomaste decisiones basadas en datos\n",
    "\n",
    "### üéØ Conceptos clave:\n",
    "\n",
    "- **Temperature**: Controla la aleatoriedad (0 = determinista, 1 = creativo)\n",
    "- **Max Tokens**: L√≠mite de longitud de respuesta\n",
    "- **Few-shot Learning**: Dar ejemplos en el prompt\n",
    "- **Chain of Thought**: Pedir al LLM que razone paso a paso\n",
    "- **Cost Tracking**: Medir tokens y costos en tiempo real\n",
    "\n",
    "### üí° Mejores pr√°cticas:\n",
    "\n",
    "1. **Siempre medir antes de optimizar**: Necesitas m√©tricas baseline\n",
    "2. **Probar m√∫ltiples configuraciones**: No hay una soluci√≥n √∫nica\n",
    "3. **Balancear calidad y costo**: M√°s tokens ‚â† mejor calidad siempre\n",
    "4. **Documentar decisiones**: Guarda las configuraciones que funcionan\n",
    "5. **Iterar basado en feedback real**: Los usuarios tienen la √∫ltima palabra\n",
    "\n",
    "### üöÄ Pr√≥ximos pasos:\n",
    "\n",
    "1. Implementa la configuraci√≥n √≥ptima en tu aplicaci√≥n\n",
    "2. Recopila feedback de usuarios reales\n",
    "3. Ajusta seg√∫n necesidades espec√≠ficas\n",
    "4. Contin√∫a a Semana 3 para t√©cnicas avanzadas\n",
    "\n",
    "---\n",
    "\n",
    "**¬°Felicidades! Has optimizado tu agente RAG de funcional a productivo. üéì**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
